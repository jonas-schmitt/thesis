\section{Formal Languages and Grammars}
In the previous section, we have introduced the theoretical background necessary to understand the fundamentals of multigrid methods.
The goal of this thesis is to develop a formal language that can express multigrid solvers of variable structure.
In general the \emph{alphabet} of a formal language is a non-empty set of symbols $\Sigma$.
Based on $\Sigma$ \emph{strings} can be created, which represent finite sequences of symbols.
For instance the alphabet $\Sigma = \left\{a, b\right\}$ contains only the symbols $a$ and $b$, as such $aabbb$ and $abaab$ are both strings on the alphabet $\Sigma$.
The length of a string, denoted by $|\cdot|$, is equal to the number of symbols contained in it. 
A concatenation of two strings 
\begin{equation}
	\begin{split}
		v & = a_1 a_2 \cdots a_n \\
		w & = b_1 b_2 \cdots b_m
	\end{split}
\end{equation}
is performed by appending the second string to the right of the first string such that
\begin{equation}
	vw = a_1 a_2 \cdots a_n b_1 b_2 \cdots b_m,
\end{equation}
The length of the concatenated string is then obviously equal to the sum of the length of the individual string, which means
\begin{equation}
|vw| = |v| + |w|.
\end{equation}
Finally, we define the empty string $\lambda$ as
\begin{equation}
	\begin{split}
		& |\lambda| = 0 \\
		& v \lambda = \lambda v = v,
	\end{split}
\end{equation}
where $v$ is a string on an arbitrary alphabet.
Assume $\Sigma$ is an alphabet, then $\Sigma^*$ is the set of strings obtained by concatenating zero or an arbitrary number of symbols from $\Sigma$.
Consequently, $\Sigma^*$ always contains the empty string $\lambda$.
To exclude $\lambda$ from the set, we define $\Sigma^+ = \Sigma^* \setminus \lambda$.
Since the number of strings that can be created from an alphabet through concatenation is infinite, both $\Sigma^+$ and $\Sigma^*$ represent infinite sets.
For example again let $\Sigma = \left\{a, b\right\}$ then
\begin{equation*}
	\Sigma^{*} = \left\{\lambda, a, b, aa, ab, ba, bb, aaa, aab, aba, \dots \right\}
\end{equation*} 
In general, for a given alphabet the \emph{language} $L$ is defined as a subset of $\Sigma^*$ (or $\Sigma^+$)
\begin{equation}
	L \supset \Sigma^*.
	\label{eq:language-basic-definition}
\end{equation}
However, in practice we usually want to obtain a language $L_G$ that represents a specific subset of $\Sigma^*$.
One way to achieve this is to define a set of rules that generate $L_G$.
These rules can be formally specified in form of a \emph{grammar}.
\begin{definition}[Grammar]
	\begin{equation*}
		G = \left(V, T, S, P \right),
	\end{equation*}
	where $V$ is a finite set of \emph{variables},
	$T$ a finite set of \emph{terminal symbols},
	$S \in V$ is the \emph{start} variable and 
	$P$ a finite set of \emph{productions} or \emph{production rules}.
	We also assume that $V \neq \emptyset$, $T \neq \emptyset$ and $V \cap T = \emptyset$.
\end{definition}
The core of a grammar are the productions $P$, which are usually specified as a set of mappings of the form
\begin{equation}
	x \to y,
	\label{eq:unrestricted-production}
\end{equation}
where $x \in \left(V \cup T\right)^+$ and $y \in \left(V \cup T\right)^*$.
Each production rule $x \to y$ can then be applied in the following way.
Given a string $u$ of the form 
\begin{equation}
	u = vxw,
\end{equation}
we can replace $x$ with $y$ to \emph{derive} a new string
\begin{equation}
	u' = vyw,
\end{equation}
which is usually written as $u \Rightarrow u'$.
This process can then be continued by applying a sequence of derivations chosen arbitrarily from the set of available productions $P$.
Within this sequence each production can be applied whenever its conditions on the left-hand side of the rule are fulfilled, i.e. the respective pattern on occurs anywhere within the current string.
Also note that there is no limit on how many times a certain productions can be applied.
Each string $u$ at which we can arrive by applying an arbitrary sequence of productions starting from $S$
\begin{equation}
	S \Rightarrow \dots \Rightarrow u,
\end{equation}
is then an element of language $L_G$.
Assuming that 
\begin{equation}
	S \overset{*}{\Rightarrow} u.
\end{equation}
represents the application of an unspecified sequence of productions, we can define the language $L_G$ generated by the grammar $G$:
\begin{definition}[Language]
	Let $G = \left\{V, T, S, P\right\}$ be a grammar, then
	\begin{equation}
		L_G = \left\{u \in T^* : S \overset{*}{\Rightarrow} u\right\}
	\end{equation}
is the language generated by $G$.
\end{definition}
Assuming $u \in L_G$ and 
\begin{equation}
	S \Rightarrow u_1 \Rightarrow u_2 \Rightarrow \dots \Rightarrow u_n \Rightarrow u
\end{equation}
is a \emph{derivation} of $u$, then the strings $S, u_1, u_2, \dots, u_n$ are called its \emph{sequential forms}.
\subsection{The Chomsky Hierarchy}
So far, we have not yet imposed any restrictions on the individual components of a grammar $G$.
We call such a grammar, whose productions are of the general form of Equation~\eqref{eq:unrestricted-production} \emph{unrestricted}.
In can be shown that any language generated by an unrestricted grammar is recursively enumerable, which means that there exists Turing machine which is capable of enumerating all strings contained in that language~\cite{linz2006introduction}.
As a consequence, one can in fact prove that unrestricted grammars are equally powerful as Turing machines and, hence, both computational models are equivalent.
Since we are only interested in languages that possess this property and, hence, can be processed by any Turing-complete system on a modern computer, there is no use in considering languages that do not fall into this category.
While Turing machines and unrestricted grammars both represent an universal model of computation, it can be useful to consider grammars that impose certain restrictions on their productions and, hence, simplify both the derivation as well as the manipulation of strings.
\emph{Context-sensitive} grammars represent a first step towards this direction.
\begin{definition}[Context-Sensitive Grammar]
A grammar $G = \left\{V, T, S, P\right\}$ is context-sensitive if all productions can be written as
\begin{equation}
	xAy \to xuy
\end{equation}
where $A \in V$ and $x, y, u \in \left(V \cup T\right)^+$.
\end{definition}
This is equivalent to say that a certain production $A \to u$ can only be peformed in the \emph{context} of $x$ and $y$, from which the term context-sensitive is derived.
While unrestricted grammars can be described by a Turing machine, the equivalent model of computation for a context-sensitive grammar is the linear bounded automaton, which represents a Turing machine whose tape is linearly bounded by the length of the string~\cite{linz2006introduction}.





   

