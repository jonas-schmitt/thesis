\section{Generalization}
The first crucial extension of our grammar-based evolutionary search method is the systematic generalization of an evolved population of multigrid methods to different instances of a PDE. 
As we have already briefly mentioned in Section~\ref{sec:fitness-evaluation-and-selection}, if properly constructed, the convergence of a multigrid method is independent of the discretization width $h$, which is usually described with the term $h$-independent convergence.
Therefore, the same method can often be successfully applied to different systems that arise from similar discretizations of the same PDE.
In Section~\ref{sec:fitness-evaluation-and-selection}, we have already introduced the idea of evaluating each multigrid solver on a number of proxy problems that possess similar properties as the problem that we are actually interested to solve.
The motivation for this idea is that, while we are usually interested in solving a problem instance of specific size, the evaluation of each solver on this instance requires too many computational resources.
As a remedy, in many cases, it is possible to construct such a set of proxy problems, by discretizing the same PDE on the given domain with a varying step size $h$.
The consequence of the $h$-independent convergence of multigrid method is that, if a functioning multigrid solver is available, it is expected to solve the problem using the same minimum number of operations per grid point.
However, as in practice, we usually do not know what the minimum number of operations per grid point is, we are instead interested in finding the multigrid method that leads to the fastest solving time $T_\varepsilon$ for the target problem with a discretization width of $h$.
The main challenge to achieve generalizations is then to identify this method among the set of candidates found within the search whereby we evaluate each candidate exclusively on instances of the same problem with a discretization width $H > h$ and, thus, smaller size.
Note that, since evolutionary algorithms are usually not guaranteed to find the global optimum, we restrict ourselves to identifying the optimum within the space of individuals sampled throughout the search.
First of all, recall that our evolutionary algorithm, whose implementation is shown in Listing~\ref{code:optimization:evolutionary_search}, performs a search by evolving a population of individuals for a specified number of generations.
In each generation, new individuals are created, by means of mutation and crossover.
However, only a limited number of individuals, chosen from the combined set of child and parent individuals, are allowed to enter the new population.
Whether an individuals is accepted for the next generation within this process solely depends on its fitness, as defined by one or multiple optimization objectives.
To achieve generalization, it is, therefore, crucial that we define the fitness of an individual in a way that maximizes the probability that the optimum, according to our criterion $T_{\varepsilon}$, is contained in the final population.
On the downside, this means that we have to prevent this individual from getting evicted from the population at any point within the search.
As we have shown in Section~\ref{sec:fitness-evaluation-and-selection} the solving time $T_{\varepsilon}$ is given by the formula
\begin{equation*}
	T_{\varepsilon} = t \cdot \frac{\ln \varepsilon}{\ln \rho},
\end{equation*}
where $t$ is the execution time per iteration and $\rho$ the (asymptotic) convergence factor of the solver.
Therefore, based on this formulate, there are two ways to define the fitness of an individual:
\begin{enumerate}
	\item Single-objective: $T_{\varepsilon}$
	\item Multi-objective:  $t$ and $\rho$
\end{enumerate}
The main difference between these two formulations is that while a single-objective evaluation always returns a single individual as the optimum, a multi-objective evaluation instead identifies a set of Pareto-optimal individual, i.e. those individuals which do not \emph{dominate} each other.
Hereby, domination is defined as the ability to achieve a better value in both objectives.
Consequently, since in the given case an improvement in each of the two objectives, $t$ and $\rho$, necessarily also leads to a faster solving time $T_{\varepsilon}$, the single-objective optimum is always contained in the Pareto-front obtained from a multi-objective evaluation of the same individuals.

The important question regarding generalization now is, whether the individual with the fastest solving time $T_{\varepsilon}$ will also be consistently selected as an optimum based on its evaluation on each problem instance considered within the search.
Here first the question arises whether the solving time $T_{\varepsilon}$, as a single-objective, leads to the same ordering of individual for each problem instance.
While in case of $h$-independent convergence, the convergence factor $\rho$ is expected to be constant, the execution time per iteration $t$ is drastically affected by hardware effects.
For instance, in case the memory requirement for a certain problem size exceeds the capacity of the cache, the execution time is expected to increase substantially compared to a problem instances that still fits into the cache\footnote{This is only true for memory-bound computations. A property that is, however, fulfilled for the majority of stencil operations.}.
As a consequence, the execution time per iteration of a multigrid method that achieves the fastest solving time for a small problem might drastically increase for a larger problem instance, which means that the solver might no longer be optimal for that problem size.
On the downside, if we consider the solver that achieves the fastest solving time for a certain problem instance.
While this method might no longer be optimal with respect to its solving time for problems of smaller size, there is a high probability that it is still contained in the Pareto-front obtained through a multi-objective evaluation.
In general, faster convergence is either achieved by applying a higher number of smoothing or coarse-grid correction steps.

Now consider the following example of two different non-dominating multigrid V-cycles.
The first one achieves a convergence factor of $0.15$ and an execution time per iteration of one millisecond using a total number of two smoothing steps per level on a grid with step size $h$, while the other one achieves a convergence factor of $0.1$ and an execution time of 1.5 milliseconds using three smoothing steps per level.
If we now consider both methods on a smaller grid with step size $2h$, it is very unlikely that the first method achieves a faster convergence than the second one.
On the other hand, three smoothing steps per level will also lead to a larger execution time per iteration for a smaller problem.
As a consequence, the dominance relation between both methods is preserved.
In contrast, assuming that the second method achieves a slightly faster solving time on the larger grid, it is impossible to predict whether this is still the case for a smaller grid.  
While considering the search for a generalizable multigrid method as a multi-objective optimization problem increases the probability that the final population contains the method with the fastest solving time for our target problem instance, this approach still has certain limitations.
If we consider different choices for each smoothing and coarse-grid correction, our assumption that a certain sequence of operations also leads to a faster execution time for a smaller problem is no longer true for each case, as certain operations might have a lower complexity and, thus, might lead to a smaller decrease in the execution time on a smaller grid.
One possibility, that has been already mentioned in Section~\ref{sec:fitness-evaluation-and-selection}, is to overcome these limitations by incorporating performance models into the evaluation, which allow to obtain a prediction for a method's execution time on a larger grid.
However, as in this thesis we only consider operations whose complexity is independent of the grid size on which they are applied, the execution time per iteration measured on a certain grid size provides a sufficient prediction for its value on a larger grid.

Based on these observations, we can now formulate an evolutionary search method for the systematic generalization of multigrid methods to a given problem class, which is summarized in Algorithm~\ref{alg:generalization-procedure}.
\begin{algorithm}
	\caption{Generalization Procedure}
	\label{alg:generalization-procedure}
	\begin{algorithmic}[1] % The number tells where the line numbering should start
		\State \textbf{Construct} the grammar $G_0$ for the initial problem
		\State \textbf{Initialize} the population $P_0$ based on $G_0$
		\State \textbf{Evaluate} $P_0$ on the initial problem with respect to $t$ and $\rho$
		\For{$i := 0, \dots, n-1$}
		\If{$i > 0$ and $i \mod m = 0$}
		\State $j := i / m$ 
		\State Increase the problem size
		\State \textbf{Construct} the corresponding grammar $G_j$
		\State  \textbf{Adapt} the current population $P_i$ to $G_j$
		\State \textbf{Evaluate} $P_i$ on the new problem with respect to $t$ and $\rho$
		\EndIf
		\State \textbf{Generate} new solutions $C_i$ based on $P_i$ and $G_j$
		\State \textbf{Evaluate} $C_i$ on the current problem with respect to $t$ and $\rho$
		\State \textbf{Select} $P_{i+1}$ from $C_i \cup P_i$
		\EndFor
		\State \textbf{Construct} the grammar $G$ for the target problem
		\State  \textbf{Adapt} the current population $P_n$ to $G$
		\State \textbf{Identify the best solver} by evaluating $P_{n}$ on the target problem
	\end{algorithmic}
\end{algorithm}
Within this procedure, the search is initiated by choosing an initial problem size.
Since at the beginning, the majority of the individuals in the population, which are generated through random initialization, are expected to represent inefficient multigrid methods, the choice of a small problem size enables the fast evaluation of a large number of individuals.
However, as the search progresses and the average quality of the individuals in the population improves, the problem size can then be iteratively increased towards the target size.
While each problem size adaption increases the required time to evaluate each method found within the search, it also increases the accuracy of evaluation with respect to both objectives.
In particular, we can only reliably test the $h$-independent convergence of a given method by evaluating it on a sequence of increasingly-larger instances of the same problem.
Furthermore, as the difference between the execution times per iteration of different non-dominating solvers decreases, even slight hardware-based fluctuations in the measurements might perturb the outcome of an evaluation.
This effect can again be reduced by considering a larger instance of the same problem, as, consequently, the relative magnitude of these fluctuations decreases compared to the overall evaluation time.
At the end of Algorithm~\ref{alg:generalization-procedure} we then obtain a population that contains a set of non-dominated individuals according to the largest problem size considered within the search.
Therefore, as discussed above, we can identify the fastest solver for our target problem instance, by only considering those individuals contained in the first non-dominated front, i.e. the population subset in which none of the individuals is dominated by any of those encountered within the search.

Finally, note that so far we have only considered increasing the problem size within the search.
However, in certain cases, a PDE contains additional parameters, which need to be adapted accordingly.
One prominent example, which we consider in this work is the indefinite Helmholtz equation, as given by
\begin{equation}
	-(\nabla^{2} + k^{2})u = f,
	\label{eq:helmholtz}
\end{equation}
where $\nabla^{2}$ is the Laplace operator, $k$ the \emph{wavenumber} and $f$ the source term.
In general, the difficulty for solving this problem increases with the value of the wavenumber $k$ .
However, many applications, for instance, require the discretization width $h$ to fulfill an accuracy requirement of $h k \leq 0.625$. 
As a consequence, in order to solve this problem on a smaller grid, we also need to adapt the wavenumber accordingly, which results in a sequence of problem instances that do not only increase in size but also in difficulty.
In Chapter~\ref{chapter:experiments}, we will then demonstrate that our generalization procedure is capable of evolving efficient multigrid methods for Helmholtz problems of varying size and difficulty.

\subsection{Implementation}
After we have now both motivated and formally described a procedure for the grammar-based evolution of generalizazible multigrid methods, the remaining step represents its successful implementation within the EvoStencils framework, as described in the last chapter.
First of all, note that the individual evolutionary operations performed within the search, i.e. initialization, mutation, crossover and selection, are all a function of the created primitive set, which means that they can be utilized in a similar way independent of the underlying problem size by registering them to the respective \emph{Toolbox} object, as shown in Listing~\ref{code:gp:toolbox}.
Furthermore, we can easily generate a grammar for different problem sizes but with a discretization hierarchy of similar depth by utilizing the \emph{generate\_grammar} function, as shown in Listing~\ref{code:grammar:generate-grammar}, while providing a different value for the argument \emph{max\_level}.
However, the essential question that has not been answered yet is how we adapt the current population to the new grammar which has been generated by increasing the problem size, as it is formulated in Line 9 of Algorithm~\ref{alg:generalization-procedure}.
To address this issue, we need to return to the original formulation of our multigrid grammar, as shown in Table~\ref{table:multigrid-grammar}.
Here note that while the level of each variable and certain terminal symbols is denoted by its subscript, each of these terms is an expression whose value depends on the discretization width $h$ on the finest level.
In other words, if we want to apply a multigrid method whose derivation tree has been generated based on a discretization hierarchy with step size $h$ and fixed depth to a different hierarchy of similar depth but with a step size of $H$, we only have to substitute the value of both step sizes in each subscript.
Now recall that in our implementation each derivation tree is represented by a \emph{PrimitiveTree} object of DEAP's GP module, which internally stores a list of each of its nodes in depth-first order.
Listing~\ref{code:gp:primitive} shows a reduced implementation of the \emph{Primitive} and \emph{Terminal} class within DEAP.
\begin{listing}
	\inputminted[linenos]{python}{evostencils/gp/primitive.py}
	\caption{GP: Primitive and Terminal class}
	\label{code:gp:primitive}
\end{listing}
The important insight that we gain from this implementation is that each \emph{Primitive} and \emph{Terminal} object is identified by the three attributes, its input types, return type and name, whereby the latter does not possess any input types.\footnote{If the second argument for the initialization of a \emph{Terminal} object is provided as a string, the \emph{terminal} and \emph{name} attributes are identical.}
Therefore, a \emph{PrimitiveTree} does not contain the complete information required for its compilation to executable Python code, but instead in addition we need to provide the respective \emph{PrimitiveSetTyped}, which then allows to construct a sequence of function applications according to the order of primitives and terminals within the tree.  
As a consequence, in case two different \emph{PrimitiveSetTyped} objects are structurally equal and employ the same name string for each of their primitives and terminals, both can be used to compile the same \emph{PrimitiveTree} object.
Now note that in Listing~\ref{code:grammar:add-terminals}, and ~\ref{code:grammar:add-level}, we generate the name string for each \emph{Primitive} and \emph{Terminal} using the problem-independent naming convention together with a subscript that corresponds to its depth in the discretization hierarchy.
As the latter is independent of the actual discretization width, each \emph{PrimitiveTree} generated based on a \emph{PrimitiveSetTyped} object returned by our \emph{generate\_grammar} function can be compiled with any other of those constructed with this function using the same value for the \emph{depth} argument\footnote{The structural equality of both objects also requires us to provide the same value for the \emph{samples} argument}.
However, while we answered the questions whether we can compile a given \emph{PrimitiveTree} using a structurally-equal but different primitive set, we have not addressed the issue of generating new individuals based on existing ones using the previously defined mutation and crossover operators.
In case of both operators, the construction of new individuals is subject to the type constraints defined within each of its \emph{Primitive} and \emph{Terminal} object.
Therefore, if we aim to construct new individuals based existing ones, that have been generated using a different \emph{PrimitiveSetTyped} object, the types of each \emph{Terminal} and \emph{Primitive} object need to match.
However, if we consider the initialization of each type in the respective method of the \emph{Types} class, as shown in Listing~\ref{code:grammar:types}, we can see that this condition is fulfilled, as all types are created as a function of the \emph{depth} argument and are, hence, independent of the details of the discretization hierarchy based on which the respective primitive set is constructed.
We can, therefore, summarize the previous discussion with the observation that while each individual contains the computational structure of the corresponding multigrid method, all required information to apply this individual to a certain discretization hierarchy is contained in the respective \emph{PrimitiveSetTyped} object.
This means that whenever we want to increase the problem size within a search, we only have to generate a new primitive set based on which we then update all operations registered at the current \emph{Toolbox} object, while, at the same time, all individuals in the population remain unchanged and only need to be reevaluated on the updated problem instance.
We can implement the resulting steps in the following method of the \emph{Optimizer} class, which is shown in Listing~\ref{code:optimization:adapt-problem-size}.
\begin{listing}
	\inputminted[linenos]{python}{evostencils/optimization/adapt_problem_size.py}
	\caption{Adapt problem size during evolution}
	\label{code:optimization:adapt-problem-size}
\end{listing}
What now remains is the integration of this method into the implementation of our evolutionary search method, as shown in Listing~\ref{code:optimization:evolutionary_search}.
However, for the sake of simplicity, we postpone this step until we have described the next major extension of our basic implementation, which is the distributed parallelization of our approach using the message passing interface (MPI).

\section{Distributed Parallelization}
As we have already discussed in Section~\ref{sec:search-space-estimation}, the size of the search space spanned by our multigrid grammar already rules out the possibility to evaluate all possible solvers that can be generated based on its productions.
However, even though the application of an evolutionary algorithm as a heuristic search method allows us to significantly reduce the number of individuals that need to be evaluated, we still have to execute each solver obtained within the search on a number of different problem instances, as described in the last section.
Furthermore, to evaluate each of these solvers, we utilize ExaStencils' capabilities to first generate a C++ implementation, which then, in a second steps needs to be compiled to an executable program.
Both steps incur a significant overhead and, hence, further increase the time required for the evaluation of each individual.
A common approach to accelerate the computationally intensive parts of an evolutionary algorithm, is to distribute their execution to several compute nodes, such that each computational step can be performed in parallel.
An overview of different approaches for the distributed parallelization of evolutionary algorithms can be found in~\cite{gong2015distributed}.
In principle, we can distinguish between approaches that are behaviorally equivalent to a sequential evolutionary algorithm and those that do not fulfill this property, usually in order to further improve the methods scalability.
Unfortunately, in general, the question which approach leads to the best outcome can not be answered easily.
However, before we decide upon a specific parallelization method, it is first important to investigate which parts of our evolutionary search method need to be parallelized in order to achieve good scalability.
According to Algorithm~\ref{alg:genetic-programming}, each generation of our evolutionary search method in principle consists of the following four steps:
\begin{enumerate}
	\item Parent Selection
	\item Child Creation
	\item Child Evaluation
	\item Population Selection
\end{enumerate}
In order to estimate the expected speedup of a parallel implementation of each of these operations, we first determine the fraction of time each of them occupies within our evolutionary search method.
For this purpose, as a representative test problem, we consider Poisson's equation on the unit square $\left[0,1\right]^2$ discretized on a uniform grid with step size $h = 1/2^{10}$ using the common five-point stencil
\begin{equation*}
	\nabla^2_h = 
	\frac{1}{h^2} \begin{bmatrix}
		& -1 & \\
		-1 & 4 & -1 \\
		& -1 &  
	\end{bmatrix},
\end{equation*}
and Dirichlet boundary conditions, which leads to a system of linear equations with 1046529 unknowns.
For the sake of simplicity, we omit the complete specification of this test problem at this point, as it will be presented in the next chapter and can be also found in~\cite{schmitt2021evostencils}.
In order to obtain representative measurements for each of the four steps of our search method, we sequentially execute our evolutionary search method for a total number 250 generations on a single socket of the Meggie compute cluster of the Erlangen Regional Computing Center\footnote{As an exception, the child evaluation step is performed in parallel on multiple sockets of the same type. Since the order of evaluation does not change the behavior of our algorithm, this decision does not affect our measurements.}.
In each generation we select $\lambda = 256$ individuals from the current population based on which we create $\lambda$ children.
Finally, we select $\mu = 256$ individuals as a new population for the next generation from the combined set of $512$ individuals using the NSGA-II non-dominated sorting procedure described in~\cite{deb2002fast}.
We then measure the average time required for each of the four steps over all generations, which is shown in Table~\ref{table:evolutionary-search-profiling}.
\begin{table}
	\caption{Average time required for each step performed within one generation of an evolutionary search for the test problem.}
	\label{table:evolutionary-search-profiling}
	\centering
	\begin{tabular}{l c}
		\toprule
		Step & Average Time \\
		\midrule
		Parent Selection & 0.68 ms \\
		\midrule
		Child Creation  & 0.32 s \\
		\midrule
		Child Evaluation  & 3.31 h \\
		\midrule
		Population Selection  & 0.20 s \\
		\bottomrule
	\end{tabular}
\end{table}
As it can be seen in this table, the overall execution time of our evolutionary search method is heavily dominated by the evaluation step, which is reflected in the fact that the combined execution times of all other steps do not even account for one percent of the overall time.
Consequently, we can drastically reduce the execution time of our evolutionary search method by performing the evaluation of multiple individuals in parallel, while the parallelization of any other step will only result in a negligible speedup. 
However, as we have to evaluate at least a single individual per compute node, the maximum achievable speedup is equal to $\lambda$, i.e., the number of children created in each generation of the search.
Finally, note that the two-dimensional Poisson equation represents a common test problem that is well known to be efficiently solvable by multigrid.
Therefore, for the majority of other PDE-based problems of similar size, we can expect a further increase in the execution time and, thus, the relative time consumption of the evaluation step.

Based on the previous discussion, we can now derive a suitable parallelization scheme for our algorithm.
However, while we have already estimated the impact of a parallel execution of each of the four steps of our method, we have not yet discussed how we can parallelize its individual operations. 
In general, if each operation within a sequence of computations is independent, which means that it is not affected by the result of any other operation in the sequence, the sequence is trivially parallelizable and can, thus, be executed completely in parallel without affecting the outcome.
As this condition is fulfilled for step 2-3 of our evolutionary algorithm, these steps can be performed in a fully parallel manner.
In contrast, both selection steps in our evolutionary search method need to access the complete population from each processing elements.
As a consequence, we can distinguish two different options to parallelize these steps on a multi-processor system:
\begin{enumerate}
	\item Duplicate the population on each processing element.
	\item Split the population into subpopulations and perform the selection on each subpopulation independently, while allowing the periodic migration between certain subpopulations. This approach is usually summarized under the term island-based evolutionary algorithm.
\end{enumerate}   
The first approach achieves behavioral equivalence to a sequential evolutionary search at the cost that both the memory and computational requirements of the resulting program increases with the population size $\mu$, which restricts its applicability to only medium-sized populations.
In contrast, depending on the amount of migration between the individual subpopulations, which require a certain amount of communication, island-based models are, in principle able to achieve unlimited scalability, as all operations are performed on completely independent subpopulations.
On the downside, since only individuals in the respective subpopulation are considered for selection, an island-based approach comprises the risk of selecting a higher percentage of inferior individuals, which might lead to slower convergence compared to its sequential counterpart.
Considering the relative low cost of selection even compared to the evaluation of a single individual\footnote{If we divide the total evaluation time per generation in Table~\ref{table:evolutionary-search-profiling} by the number of children, we obtain an average evaluation time of 47 seconds per individual.}, as demonstrated for the given test problem with a population size of $\mu = 256$, we can deduce that a duplication of the whole population is feasible for most experiments performed on small to medium-sized clusters.
However, in case extremely-large populations are needed, an island-based approach offers the additional possibility to scale our evolutionary search methods to large scale systems, such as supercomputers.

To parallelize our evolutionary search method on a multi-node system, such that the evaluation of each individual can be performed on a single multi-core compute node, we utilize the message passing library (MPI), which is available in form of the MPI for Python (mpi4py) package.
While MPI only defines interfaces for the C and Fortran programming languages, mpi4py provides an additional layer of abstractions which enables the exchange of arbitrary Python objects between different processes using Python's Pickle library.
Pickle provides a unified way to serialize and deserialize objects using a portable binary format, which can then be transmitted using the core functionality provided by MPI.
Since MPI represents the de facto standard for distributed computing and is, thus, supported on the majority of high-performance computing systems, its use facilitates the portability of our implementation.
Furthermore, the availability of highly-optimized MPI implementations, which are often developed in cooperation with hardware manufacturers\footnote{For instance Intel MPI is available on most systems using Intel CPUs.}, enables the communication between different processors in an highly-efficient manner.
As a first step to parallelize our evolutionary search method using mpi4py, we extend the previously defined \emph{Optimizer} class as shown in Listing~\ref{code:optimization:optimizer} to provide an interface to all required MPI operations. 



\section{Systems of Partial Differential Equations}