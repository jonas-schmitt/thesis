In the following, we will discuss two extensions of the evolutionary program synthesis framework described in the last chapter, which are crucial for the effective application of our approach to many applications: \emph{Generalization} and \emph{parallelization}.  
First of all, to discover multigrid methods that are capable of solving different instances of a PDE, we are concerned with their generalizability.
For this purpose, we will derive an adapted version of our original evolutionary algorithm that utilizes the special properties of multigrid methods.
Furthermore, since the successful application of this method requires the code generation-based evaluation of a large number of individuals, we will present a distributed parallelization scheme, which enables the execution of our implementation on current multi-node computing systems.
In the final chapter of this thesis, we will then demonstrate how the implementation described here can be successfully applied to different PDEs, yielding multigrid-based solvers that are competitive with hand-optimized methods. 

\section{Generalization}
\label{sec:generalization}
As we have briefly discussed in Section~\ref{sec:fitness-evaluation-and-selection}, if properly constructed, the error reduction capabilities of a multigrid method are independent of the discretization width $h$, which is usually described with the term $h$-independent convergence.
Therefore, the same method can often be successfully applied to different systems that arise from similar discretizations of the same PDE.
We have already introduced the idea of evaluating each multigrid method on a number of proxy applications whose properties are similar to the problem that we actually aim to solve.
The motivation for this idea is that, while we are usually interested in solving a problem instance of a specific size, the evaluation of each solver on this instance requires an excessive amount of computational resources.
In many cases, it is possible to construct such a set of proxy applications by discretizing the same PDE with varying step sizes $h$.
If we are able to design a solver that achieves $h$-independent convergence, it can be expected to solve each of these proxy applications using the same number of operations per grid point.
In addition to this requirement, we want to identify the method that leads to the fastest solving time $T_\varepsilon$ for the target problem with a discretization width of $h$.
The main challenge is thus to identify this method within the evolved population while performing the majority of evaluations on smaller problem instances with a discretization width $H > h$.
Note that since evolutionary algorithms are usually not guaranteed to find the global optimum, we restrict ourselves to identifying the optimum among the individuals discovered while evolving the population.
%First of all, recall that our evolutionary algorithm, whose implementation can be found in Listing~\ref{code:optimization:evolutionary_search}, performs a search by evolving a population of individuals for a specified number of generations.
In each generation, new individuals are created by applying mutation and crossover.
However, only a limited number of individuals, chosen from the combined set of child and parent individuals, are allowed to enter the new population.
Whether an individual is accepted for the next generation solely depends on its fitness, as defined by one or multiple objectives.
Therefore, to achieve generalization, it is crucial that we define the fitness of an individual in a way that maximizes the probability that the optimum, according to our criterion $T_{\varepsilon}$, is contained in the final population.
We thus have to prevent the eviction of this individual from the population at any point in the algorithm.

\subsection{Objective Function Definition}
\label{sec:generalization:objective-function-definition}
As we have shown in Section~\ref{sec:fitness-evaluation-and-selection} the solving time $T_{\varepsilon}$ is given by the formula
\begin{equation*}
	T_{\varepsilon} = t \cdot \frac{\ln \varepsilon}{\ln \rho},
\end{equation*}
where $t$ is the execution time per iteration and $\rho$ the (asymptotic) convergence factor of the solver.
Therefore, based on this formulation, there are two ways to define the fitness of an individual:
\begin{enumerate}
	\item Single-objective: $T_{\varepsilon}$
	\item Multi-objective:  $t$ and $\rho$
\end{enumerate}
The main difference here is that while a single-objective evaluation always returns a single individual as the optimum, a multi-objective evaluation instead identifies a set of Pareto-optimal individuals, i.e., individuals which do not \emph{dominate} each other, which means that they are unable to achieve a better value in both objectives.
Since, in the given case, an improvement in either of the two objectives, $t$ and $\rho$, necessarily leads to a faster solving time $T_{\varepsilon}$, the single-objective optimum is always contained in the Pareto-front obtained from a multi-objective evaluation of the same individuals.
Therefore, the major question for generalization is whether the individual with the fastest solving time $T_{\varepsilon}$ for our target problem will be consistently selected as an optimum when it is evaluated on smaller instances of the same problem.
Unfortunately, the solving time $T_{\varepsilon}$, as a single objective, does not lead to the same ranking of individuals for each problem instance.
While the convergence factor $\rho$ of a functioning multigrid method is expected to be constant, its execution time per iteration $t$ is drastically affected by hardware effects.
For instance, if the memory requirement for a certain problem size exceeds the capacity of the cache, the execution time is expected to increase substantially compared to a problem instance that still fits into the cache\footnote{This is only true for memory-bound computations. A property that is, however, fulfilled for the majority of stencil operations.}.
As a consequence, the execution time per iteration of a multigrid method that achieves the fastest solving time for a small problem might drastically increase for a larger problem instance, which means that the solver might no longer be optimal for that problem size.
%On the downside, if we consider the solver that achieves the fastest solving time for a certain problem instance.
%While this method might no longer be optimal with respect to its solving time for problems of smaller size, there is a high probability that it is still contained in the Pareto-front obtained through a multi-objective evaluation.
%In general, faster convergence is either achieved by applying a higher number of smoothing or coarse-grid correction steps.

Now consider the following example of two different non-dominating multigrid V-cycles.
The first one achieves a convergence factor of 0.15 and an execution time per iteration of one millisecond using a total number of two smoothing steps per level on a grid with step size $h$, while the other one achieves a convergence factor of 0.1 and an execution time of 1.5 milliseconds using three smoothing steps per level.
If we now execute both methods on a smaller grid with step size $2h$, it is very unlikely that the first method achieves faster convergence than the second one.
On the other hand, three smoothing steps per level will also lead to a larger execution time per iteration for a smaller problem.
As a consequence, the dominance relation between both methods is preserved.
In contrast, assume that the second method achieves a slightly faster solving time on the larger grid.
Since it is impossible to predict the order of magnitude of change in the value of $t$ for both methods without actually executing them, we can not be sure whether this is still the case for a smaller grid.
While treating the search for a generalizable multigrid method as a multi-objective optimization problem, therefore, increases the probability that the final population contains the fastest solver for our target problem instance, this approach still has limitations.
If we consider different choices for each smoothing and coarse-grid correction step, our assumption that a certain sequence of operations also leads to a faster execution time for a smaller problem size is no longer true for each case, as certain operations might have lower complexity and, thus, could lead to a smaller decrease in the execution time on a smaller grid.
A simple example of such an operation is line smoothing which becomes significantly more expensive on a larger grid on~\cite{trottenberg2000multigrid}.
One caveat for this problem that has already been mentioned in Section~\ref{sec:fitness-evaluation-and-selection} is to incorporate performance models into the evaluation, which can yield a prediction for a method's execution time on a larger grid.
However, within the scope of this work, we only consider operations whose complexity is independent of the grid size, i.e., pointwise smoothers and block smoothers with blocks of fixed size. 
Therefore, the execution time per iteration measured on a certain grid size provides a sufficient prediction for its value on a larger grid.

\subsection{Generalization Procedure}
\label{sec:generalization-procedure}
Based on these observations, we can now formulate an evolutionary search method for the systematic generalization of multigrid methods to a given problem class, which is summarized in Algorithm~\ref{alg:generalization-procedure}.
\begin{algorithm}
	\caption{Generalization Procedure}
	\label{alg:generalization-procedure}
	\begin{algorithmic}[1] % The number tells where the line numbering should start
		\State \textbf{Construct} the grammar $G_0$ for the initial problem
		\State \textbf{Initialize} the population $P_0$ based on $G_0$
		\State \textbf{Evaluate} $P_0$ on the initial problem with respect to $t$ and $\rho$
		\For{$i := 0, \dots, n-1$}
		\If{$i > 0$ and $i \mod m = 0$}
		\State $j := i / m$ 
		\State Increase the problem size
		\State \textbf{Construct} the corresponding grammar $G_j$
		\State  \textbf{Adapt} the current population $P_i$ to $G_j$
		\State \textbf{Evaluate} $P_i$ on the new problem with respect to $t$ and $\rho$
		\EndIf
		\State \textbf{Generate} new solutions $C_i$ based on $P_i$ and $G_j$
		\State \textbf{Evaluate} $C_i$ on the current problem with respect to $t$ and $\rho$
		\State \textbf{Select} $P_{i+1}$ from $C_i \cup P_i$
		\EndFor
		\State \textbf{Construct} the grammar $G$ for the target problem
		\State  \textbf{Adapt} the current population $P_n$ to $G$
		\State \textbf{Identify the best solver} by evaluating $P_{n}$ on the target problem
	\end{algorithmic}
\end{algorithm}
Within this procedure, the search begins by choosing an initial problem size.
Since, at this point, the majority of the individuals in the population, which are generated through random initialization, are expected to represent inefficient multigrid methods, the choice of a small problem size enables the fast evaluation of a large number of individuals.
However, as the search progresses and the average quality of the individuals in the population improves, the problem size can then be iteratively increased toward the target size.
While each problem size adaption increases the required time to evaluate each method found within the search, it also improves the accuracy of evaluation with respect to both objectives.
As discussed in Section~\ref{sec:generalization:objective-function-definition}, we can, furthermore, test the $h$-independent convergence of a given method by evaluating it on a sequence of increasingly-larger instances of the same problem.
Also, note that if there is only a small difference between the execution times per iteration of non-dominating solvers, even slight hardware-based fluctuations in the measurements might perturb the outcome of an evaluation.
This effect can again be reduced by considering a larger instance of the same problem, as the relative magnitude of these fluctuations decreases compared to the overall evaluation time.
At the end of Algorithm~\ref{alg:generalization-procedure} we obtain a population that contains a set of non-dominated individuals according to the largest problem size considered within the search.
We can, thus, identify the fastest solver for our target problem instance by only considering those individuals contained in the first non-dominated front, i.e., the population subset in which none of the individuals is dominated by any of those encountered within the search.

Finally, note that so far, we have only considered increasing the problem size within the search.
However, in certain cases, a PDE contains additional parameters which need to be adapted accordingly.
One prominent example, which we consider in this work, is the indefinite Helmholtz equation, as given by
\begin{equation}
	-(\nabla^{2} + k^{2})u = f,
	\label{eq:helmholtz}
\end{equation}
where $\nabla^{2}$ is the Laplace operator, $k$ the \emph{wavenumber} and $f$ the source term.
In general, the difficulty of solving this problem increases with the value of the wavenumber $k$.
However, many applications, for instance, require the discretization width $h$ to fulfill an accuracy requirement of $h k \leq 0.625$. 
As a consequence, in order to solve this problem on a smaller grid, we also need to adapt the wavenumber accordingly, which results in a sequence of problem instances not only increasing in size but also in their difficulty.
In Chapter~\ref{chapter:experiments}, we will demonstrate that our generalization procedure yields efficient multigrid methods for Helmholtz problems of varying size and difficulty.

\subsection{Implementation}
After we have now both motivated and described a procedure for the grammar-based design of generalizable multigrid methods, the remaining step is its successful implementation within the EvoStencils framework.
First of all, note that the individual evolutionary operators, i.e., initialization, mutation, crossover, and selection, are all implemented based on the created \emph{PrimitiveSetTyped} object. 
Their application is, thus, independent of the underlying problem size, but we only have to register them to the respective \emph{Toolbox} object, as shown in Listing~\ref{code:gp:toolbox}.
Furthermore, we can easily generate a grammar for different problem sizes with a discretization hierarchy of similar depth by utilizing the \emph{generate\_grammar} function, as shown in Listing~\ref{code:grammar:generate-grammar}, while providing a different value for the argument \emph{max\_level}.
However, the essential question that has not been answered yet is how we then adapt the current population to the resulting new grammar, as it is formulated in Line~9 of Algorithm~\ref{alg:generalization-procedure}.
To address this issue, we need to return to the original formulation of our multigrid grammar, as shown in Table~\ref{table:multigrid-grammar}.
Note that while the level of each variable and certain terminal symbols is denoted by its subscript, each of these terms is an expression whose value depends on the step size $h$ of the finest grid.
In other words, if we want to apply a multigrid method whose derivation tree has been generated based on a discretization hierarchy with step size $h$ and fixed depth to a different hierarchy of similar depth but with a step size of $H$, we only have to substitute the value of both step sizes in each subscript.
Now recall that in our implementation, each derivation tree is represented by a \emph{PrimitiveTree} object of DEAP's GP module, which internally stores a list of its nodes in depth-first order.
Listing~\ref{code:gp:primitive} shows a reduced implementation of the \emph{Primitive} and \emph{Terminal} class within DEAP.
\begin{listing}
	\inputminted{python}{evostencils/gp/primitive.py}
	\caption{GP: Primitive and Terminal class}
	\label{code:gp:primitive}
\end{listing}
According to this implementation, each \emph{Primitive} and \emph{Terminal} object is identified by three attributes: Its argument types, return type, and name.
Note that a \emph{Terminal} object does not possess any input types, and if the second argument for its initialization is provided as a string, the \emph{terminal} and \emph{name} attributes are identical.
Therefore, a \emph{PrimitiveTree} does not contain the complete information required for its compilation to executable Python code, but we, additionally, need to provide the respective \emph{PrimitiveSetTyped} object.
This then allows us to construct a sequence of function applications according to the order of nodes within the tree.  
As a consequence, in case two different \emph{PrimitiveSetTyped} objects are structurally equal and employ the same name string for each of their primitives and terminals, both can be used to compile the same \emph{PrimitiveTree} object.
Now note that in Listing~\ref{code:grammar:add-terminals}, and~\ref{code:grammar:add-level}, we generate the name string for each \emph{Primitive} and \emph{Terminal} using the problem-independent naming convention together with a subscript that corresponds to its depth in the discretization hierarchy.
As the latter is independent of the actual step size of the grid, each \emph{PrimitiveTree} generated based on a \emph{PrimitiveSetTyped} object returned by our \emph{generate\_grammar} function can be compiled by any other \emph{PrimitiveSetTyped} object that has been obtained using the same value for the \emph{depth} argument\footnote{The structural equality of both objects also requires us to provide the same value for the \emph{samples} argument}.
While this provides us with a way to compile a given \emph{PrimitiveTree} after replacing our previous \emph{PrimitiveSetTyped} object with a new one, we have not yet addressed the questions of how this affects the generation of new individuals by means of mutation and crossover.
In the case of both operators, the construction of new individuals is subject to the type constraints defined within each of its \emph{Primitive} and \emph{Terminal} objects.
Therefore, if we aim to construct new individuals based on existing ones that have been generated using a different \emph{PrimitiveSetTyped} object, the types of the respective \emph{Terminal} and \emph{Primitive} object need to match.
If we consider the initialization of each type in the respective method of the \emph{Types} class, as shown in Listing~\ref{code:grammar:types}, we can see that this condition is fulfilled since all types are created as a function of the \emph{depth} argument.
Each type is, thus, independent of the details of the discretization hierarchy based on which a \emph{PrimitiveSetTyped} object is constructed.
Therefore, we can summarize the previous discussion with the observation that while each individual contains the computational structure of the corresponding multigrid method, all required information to apply this individual to a certain discretization hierarchy is contained in the respective \emph{PrimitiveSetTyped} object.
This means that whenever we want to increase the problem size within our evolutionary program synthesis procedure, we only have to generate a new \emph{PrimitiveSetTyped} object based on which we then update all operations registered at the current \emph{Toolbox} object.
At the same time, all individuals in the population remain unchanged and only need to be reevaluated on the updated problem instance.
We can implement the resulting steps in the following method of the \emph{Optimizer} class, which is shown in Listing~\ref{code:optimization:adapt-problem-size}.
\begin{listing}
	\inputminted{python}{evostencils/optimization/adapt_problem_size.py}
	\caption{Problem size adaption during the evolutionary search}
	\label{code:optimization:adapt-problem-size}
\end{listing}
What now remains is the integration of this method into the implementation of our evolutionary search method, as shown in Listing~\ref{code:optimization:evolutionary_search}.
However, we postpone this step until we have described the next major extension of our basic implementation, which is the distributed parallelization of our approach using the message-passing interface (MPI).

\section{Distributed Parallelization}
\label{sec:distributed-parallelization}
As we have already discussed in Section~\ref{sec:search-space-estimation}, the size of the search space spanned by our grammar rules out the possibility of evaluating the entirety of multigrid methods that can be generated based on its productions.
However, even though the application of an evolutionary algorithm as a heuristic search method allows us to significantly reduce the number of considered individuals, we still have to execute a large number of solvers on different problem instances.
Furthermore, to evaluate each of these solvers, we make use of ExaStencils' capabilities to automatically generate a C++ implementation, which then, in a second step, needs to be compiled into an executable program.
Both steps induce a significant overhead and, hence, further increase the time required for the evaluation of each individual.
A common approach to accelerate the computationally intensive parts of an evolutionary algorithm is to distribute their execution to several compute nodes such that each computational step can be performed in parallel.
An overview of different approaches for the distributed parallelization of evolutionary algorithms can be found in~\cite{gong2015distributed}.
In principle, we can distinguish between approaches that are behaviorally equivalent to a sequential evolutionary algorithm and those that do not fulfill this property, usually in order to further improve the algorithm's scalability.
Unfortunately, in general, which approach leads to the best outcome can not be answered easily.
Before deciding on a specific parallelization method, we first need to investigate which parts of our evolutionary search method need to be parallelized to achieve good scalability.

\subsection{Empirical Execution Time Analysis}
\label{sec:execution-time-analysis}
According to Algorithm~\ref{alg:genetic-programming}, each step of our evolutionary search method, in principle, consists of the following four operations:
\begin{enumerate}
	\item Parent Selection
	\item Child Creation
	\item Child Evaluation
	\item Population Selection
\end{enumerate}
In order to estimate the expected speedup of a parallel implementation of each of these operations, we first determine their fraction of the total execution time of our evolutionary search method.
For this purpose, we consider Poisson's equation on the unit square $\left[0,1\right]^2$ discretized on a uniform grid with step size $h = 1/2^{11}$ using the common five-point stencil
\begin{equation*}
	\nabla^2_h = 
	\frac{1}{h^2} \begin{bmatrix}
		0 & 1 & 0\\
		1 & -4 & 1 \\
		0 & 1 & 0  
	\end{bmatrix},
\end{equation*}
and Dirichlet boundary conditions, which leads to a system of linear equations with $4\,190\,209$ unknowns.
For the sake of simplicity, we omit the complete specification of this test problem at this point, which can be found in Section~\ref{sec:poisson-equation}.
In order to obtain representative measurements for each of the four steps of our search method, we execute our evolutionary program synthesis method sequentially for a total number of 250 generations on a single socket of the Meggie compute cluster of the Erlangen Regional Computing Center\footnote{As an exception, the child evaluation step is performed in parallel on multiple sockets of the same type. Since the order of evaluation does not change the behavior of our algorithm, this decision does not affect our measurements.}.
In each generation, we select $\lambda = 256$ individuals from the current population, based on which we create $\lambda$ children.
Finally, we select $\mu = 256$ individuals as a new population for the next generation from the combined set of $512$ individuals using the NSGA-II non-dominated sorting procedure described in~\cite{deb2002fast}.
We then measure the average time required for each of the four steps over all generations, which is shown in Table~\ref{table:evolutionary-search-profiling}.
\begin{table}
	\caption{Average time required for each step performed within one generation of an evolutionary search for the test problem.}
	\label{table:evolutionary-search-profiling}
	\centering
	\begin{tabular}{l c}
		\toprule
		Step & Average Time \\
		\midrule
		Parent Selection & 0.68 ms \\
		\midrule
		Child Creation  & 0.32 s \\
		\midrule
		Child Evaluation  & 3.31 h \\
		\midrule
		Population Selection  & 0.20 s \\
		\bottomrule
	\end{tabular}
\end{table}
According to these measurements, the overall execution time of our evolutionary program synthesis method is heavily dominated by the evaluation step, which is reflected in the fact that the combined execution times of all other steps do not even account for one percent of the overall time.
Consequently, we can drastically reduce the execution time of our approach by performing the evaluation of multiple individuals in parallel, while the parallelization of any other step will only result in a negligible speedup. 
However, as we have to evaluate at least a single individual per compute node, the maximum achievable speedup is equal to $\lambda$, i.e., the number of children created in each generation of our method.
Finally, note that the two-dimensional Poisson equation represents a common test problem that is well known to be efficiently solvable by multigrid.
Therefore, for the majority of other PDE-based problems of similar size, we can expect a further increase in the execution time and, hence, in the relative time consumption of the evaluation step.

\subsection{Parallelization Method}
Based on the previous discussion, we can now derive a suitable parallelization scheme for our algorithm.
However, while we have already estimated the impact of parallel execution of each of the four steps of our method, we have not yet discussed how we can parallelize its individual operations on a given number of processing units. 
In general, if each operation within a sequence of computations can be performed independently, which means that it is not affected by the result of any other operation, the sequence is trivially parallelizable.
As this condition is fulfilled for steps 2--3 of our evolutionary algorithm, these operations can be performed in a fully parallel manner.
In contrast, in both selection steps of our method, each processing unit needs to access the complete population.
As a consequence, we can distinguish two fundamentally different ways to parallelize these steps on a multi-processor system:
\begin{enumerate}
	\item Duplicate the population on each processing unit.
	\item Split the population into subpopulations and perform the selection on each of them independently while allowing the periodic migration between certain subpopulations. Usually, to describe this approach, the term island-based evolutionary algorithm is used.
\end{enumerate}   
The first approach achieves behavioral equivalence to a sequential evolutionary search at the cost that both the memory and computational requirements of the resulting program increase with the population size $\mu$, which restricts its applicability to only medium-sized populations.
In contrast, depending on the amount of migration between the individual subpopulations, which require a certain amount of communication, island-based models can, in principle, yield unlimited scalability since all operations are performed on completely independent subpopulations.
On the downside, as only individuals in the respective subpopulation are considered for selection, an island-based approach comprises the risk of selecting a higher percentage of inferior individuals, which might lead to slower convergence compared to its sequential counterpart.
Considering the relatively low cost of selection even compared to the evaluation of a single individual\footnote{If we divide the total evaluation time per generation in Table~\ref{table:evolutionary-search-profiling} by the number of children, we obtain an average evaluation time of 47 seconds per individual.}, as demonstrated for the given test problem with a population size of $\mu = 256$, we can conclude that a duplication of the whole population is feasible for most experiments performed on small to medium-sized compute clusters.
It is, therefore, the chosen method of parallelization within our implementation.
While this decision theoretically limits scalability, for all experiments considered in this work, which do not employ populations larger than 256 individuals, a duplication of the complete population is feasible.
However, an island-based parallelization can be considered a viable future extension for potential applications that require us to perform an evolutionary search with significantly larger population sizes.

\subsection{Implementation}
After describing our parallelization approach, we can now proceed with its implementation as an extension of our previously defined \emph{Optimizer} class.
For this purpose, we utilize the message-passing interface (MPI), which is available in the form of the MPI for Python (mpi4py) package.
While MPI only defines interfaces for the C and Fortran programming languages, mpi4py provides an additional layer of abstractions that enables the exchange of arbitrary Python objects between different processes using Python's Pickle library.
As we have already described in Section~\ref{sec:evostencils-part1:productions}, Pickle provides a unified way to serialize and deserialize objects based on a portable binary format, which can then be transmitted using the core functionality provided by MPI.
Since MPI represents the de facto standard for distributed computing and is, thus, supported on the majority of high-performance computing systems, its usage facilitates the portability of our implementation.
Furthermore, the availability of highly-optimized MPI implementations, which are often developed in cooperation with hardware manufacturers\footnote{For instance, Intel MPI is available on most systems with Intel CPUs.}, enables the communication between different processors in a highly-efficient manner.
As a first step towards the parallelization of our evolutionary program synthesis method with mpi4py, we extend the previously defined \emph{Optimizer} class found in Listing~\ref{code:optimization:optimizer-mpi} by providing an interface to all required MPI operations. 
\begin{listing}
	\inputminted[linenos]{python}{evostencils/optimization/optimizer_mpi.py}
	\caption{Optimizer class: MPI extension}
	\label{code:optimization:optimizer-mpi}
\end{listing}
Therefore, we include the MPI communicator object, the number of processes, and the process rank as additional arguments of the initialization method.
Note that all MPI operations can then be performed solely based on this information and the respective communicator object.
In order to exchange individuals between the processes, we utilize the \emph{allgather} operation, which first collects a list of objects from all processes that are then distributed to each individual process.
Therefore, as in our case, each of these objects corresponds to a list of individuals, we additionally employ the \emph{merge\_lists} function to merge all sublists into a single list, which then contains the individuals collected from all processes.
Note that in case only a single process exists, we simply return the object passed to the method without modification, which provides a unified interface for the sequential and parallel execution of our evolutionary search method.
The resulting operation is then implemented in Lines~18--22 of Listing~\ref{code:optimization:optimizer-mpi}. 

As a final step, we can now make use of this interface to implement a parallel version of the generalization procedure described in Algorithm~\ref{alg:generalization-procedure} as an extension of the basic implementation of our evolutionary program synthesis method discussed in Section~\ref{sec:evostencils-part1:search-algorithm}.
The resulting Python implementation is shown in Listing~\ref{code:optimization:evolutionary-search-mpi}, where we have omitted the implementation of the random search for the sake of brevity.
\begin{listing}
	\inputminted[linenos]{python}{evostencils/optimization/evolutionary_search_mpi.py}
	\caption{Evolutionary Search Method}
	\label{code:optimization:evolutionary-search-mpi}
\end{listing}
Since most of the required functionality is already implemented within the \emph{adapt\_problem\_size} and \emph{allgather} methods, only a few adaptions of our original implementation are required.
First of all, we include an additional argument \emph{generalization\_interval}, which corresponds to the parameter $m$ in Algorithm~\ref{alg:generalization-procedure}.
Based on the value of this argument, we iteratively increase the problem size after a specified number of generations.
Finally, we parallelize the individual steps of our evolutionary search method using the previously defined MPI interface.
According to the MPI programming model, if the number of processes is larger than one, each process executes its own instance of the same program.
We, thus, only have to implement the required synchronization points between the processes.
Similar to our original implementation, the first step within our evolutionary program synthesis method is the generation and evaluation of an initial population.
Therefore, in Lines~7--10, each process first generates and evaluates its respective fraction of the initial population, which is then combined and distributed using the \emph{allgather} method in Line~11.
In a similar fashion, each process generates its fraction of the offspring by first selecting the respective number of parents, based on which new individuals are created in Lines~29--31 by applying crossover and mutation.
Again, after each process has finished the evaluation of its local individuals, the combined offspring is obtained using the \emph{allgather} method in Line~35.
Since after this operation, each process has an exact copy of all newly-created individuals, the following elitist selection in Line~38 consistently leads to the same population, based on which the search then proceeds until the maximum number of generations has been reached.

With the implementation of a scalable evolutionary program synthesis method that is able to utilize the compute capabilities of current multi-node systems, we can now evaluate the effectiveness of our approach for the grammar-based design of multigrid methods in a number of experiments, where we consider two common PDE-based model problems, Poisson's equation, and a linear elastic boundary value problem.
Furthermore, as a final evaluation step, we assess the efficiency and generalizability of the solvers evolved within the generalization procedure described in Algorithm~\ref{alg:generalization-procedure} on a difficult benchmark problem, the indefinite Helmholtz equation with increasingly-large wavenumbers.

% TODO Maybe include this section again
%\section{Systems of Partial Differential Equations}