In the following, we will discuss two extensions of the evolutionary program synthesis framework described in the last chapter, which are crucial for the effective application of our approach to many applications - \emph{generalization} and \emph{parallelization}.  
First of all, to discover multigrid methods that are capable of solving different instances of a PDE, we are concerned with their generalizability.
For this purpose, we will derive an adapted version of our original evolutionary algorithm that utilizes the special properties of multigrid methods.
Furthermore, since the successful application of this method requires the code generation-based evaluation of a large number of individuals, we will present a distributed parallelization scheme, which enables the execution of our implementation on current multi-node computing systems.
In the final chapter of this thesis, we will then demonstrate how the implementation described here can be successfully applied to different PDEs, yielding multigrid-based solvers that are competitive with hand-optimized methods. 

\section{Generalization}
\label{sec:generalization}
As we have briefly discussed in Section~\ref{sec:fitness-evaluation-and-selection}, if properly constructed, the error reduction capabilities of a multigrid method are independent of the discretization width $h$, which is usually described with the term $h$-independent convergence.
Therefore, the same method can often be successfully applied to different systems that arise from similar discretizations of the same PDE.
We have already introduced the idea of evaluating each multigrid method on a number of proxy applications whose properties are similar to the problem that we actually aim to solve.
The motivation for this idea is that, while we are usually interested in solving a problem instance of a specific size, the evaluation of each solver on this instance requires an excessive amount of computational resources.
In many cases, it is possible to construct such a set of proxy applications by discretizing the same PDE with varying step sizes $h$.
If we are able to design a solver that achieves $h$-independent convergence, it can be expected to solve each of these proxy applications using the same number of operations per grid point.
In addition to this requirement, we want to identify the method that leads to the fastest solving time $T_\varepsilon$ for the target problem with a discretization width of $h$.
The main challenge is thus to identify this method within the evolved population while performing the majority of evaluations on smaller problem instances with a discretization width $H$ greater than $h$.
Note that since evolutionary algorithms are usually not guaranteed to find the global optimum, we restrict ourselves to identifying the optimum among the individuals discovered while evolving the population.
%First of all, recall that our evolutionary algorithm, whose implementation can be found in Listing~\ref{code:optimization:evolutionary_search}, performs a search by evolving a population of individuals for a specified number of generations.
In each generation, new individuals are created by applying mutation and crossover.
However, only a limited number of individuals, chosen from the combined set of child and parent individuals, are allowed to enter the new population.
Whether an individual is accepted for the next generation solely depends on its fitness, as defined by one or multiple objectives.
Therefore, to achieve generalization, it is crucial that we define the fitness of an individual in a way that maximizes the probability that the optimum, according to our criterion $T_{\varepsilon}$, is contained in the final population.
We thus have to prevent the eviction of this individual from the population at any point during the execution of our algorithm.

\subsection{Objective Function Definition}
\label{sec:generalization:objective-function-definition}
As we have shown in Section~\ref{sec:fitness-evaluation-and-selection} the solving time $T_{\varepsilon}$ is given by the formula
\begin{equation*}
	T_{\varepsilon} = t \cdot \frac{\ln \varepsilon}{\ln \rho},
\end{equation*}
where $t$ is the execution time per iteration and $\rho$ the (asymptotic) convergence factor of the iterative solver.
Therefore, there are two ways to define the fitness of an individual based on this metric:
\begin{enumerate}
	\item Single-objective: $T_{\varepsilon}$
	\item Multi-objective:  $t$ and $\rho$
\end{enumerate}
The main difference here is that while a single-objective evaluation always returns a single individual as the optimum, a multi-objective evaluation instead identifies a set of Pareto-optimal individuals, i.e., individuals that do not \emph{dominate} each other, which means that they are unable to achieve a better value in both objectives.
Since in the given case, an improvement in either of the two objectives, $t$ and $\rho$, necessarily leads to a faster solving time $T_{\varepsilon}$, the single-objective optimum is always contained in the Pareto-front obtained from a multi-objective evaluation of the same individuals.
Therefore, the main question regarding generalization is whether the individual with the fastest solving time $T_{\varepsilon}$ for our target problem will be consistently selected as an optimum when it is evaluated on smaller instances of the same problem.
First of all, note that the solving time $T_{\varepsilon}$, as a single objective, does not necessarily lead to the same ranking of individuals for each problem instance.
While the convergence factor $\rho$ of a functioning multigrid method executed as an iterative solver is expected to be constant, its execution time per iteration $t$ is drastically affected by hardware effects.
For instance, if the memory requirement for a certain problem size exceeds the capacity of the cache, the execution time is expected to increase substantially compared to a problem instance that still fits into the cache\footnote{This is only true for memory-bound computations. A property that is, however, fulfilled for the majority of stencil operations.}.
As a consequence, the execution time per iteration of a multigrid method that achieves the fastest solving time for a small problem might drastically increase for a larger problem instance, which means that the solver might no longer be optimal.
%On the downside, if we consider the solver that achieves the fastest solving time for a certain problem instance.
%While this method might no longer be optimal with respect to its solving time for problems of smaller size, there is a high probability that it is still contained in the Pareto-front obtained through a multi-objective evaluation.
%In general, faster convergence is either achieved by applying a higher number of smoothing or coarse-grid correction steps.

Now consider an example of two different non-dominating multigrid V-cycles.
The first cycle uses two smoothing steps per level leading to a convergence factor of 0.15 and an execution time per iteration of one millisecond on a grid with step size $h$, while the second one achieves a convergence factor of 0.1 and an execution time of 1.5 milliseconds using three smoothing steps per level.
If we now execute both methods on a smaller grid with step size $2h$, it is very unlikely that the first cycle will converge faster than the second one.
Likewise, three smoothing steps per level will also lead to a higher execution time per iteration for a smaller problem.
As a consequence, the dominance relation between both methods is preserved.
In contrast, assume that the second method achieves a slightly faster solving time on the larger problem.
Since it is impossible to predict the order of magnitude of change in the value of $t$ for both methods without actually executing them, we can not be sure whether this is still the case for a smaller problem.
While treating the design of a generalizable multigrid method as a multi-objective optimization problem increases the probability that the final population contains the fastest solver, this approach still has limitations.
If we consider different choices for each smoothing and coarse-grid correction step, our assumption that a certain sequence of operations also leads to a faster execution time for a smaller problem size is no longer a certainty, as some operations might possess a different computational complexity.
A simple example of such an operation is line smoothing which becomes significantly more expensive when it is applied to larger problems~\cite{trottenberg2000multigrid}.
One caveat for this issue, which has already been mentioned in Section~\ref{sec:fitness-evaluation-and-selection}, is to predict the execution time of a solver with a performance model~\cite{williams2009roofline,hager2016exploring}.
However, since in this work, we only consider operations whose complexity is independent of the problem size, i.e., pointwise smoothers and block smoothers with blocks of fixed size, the measured execution time per iteration provides a sufficient prediction for larger instances of the same problem.

\subsection{Generalization Procedure}
\label{sec:generalization-procedure}
Based on the observations made in the last section, we can now formulate an extension of our evolutionary algorithm for the systematic generalization of multigrid methods to a given problem class, which is summarized in Algorithm~\ref{alg:generalization-procedure}.
\begin{algorithm}
	\caption{Generalization Procedure}
	\label{alg:generalization-procedure}
	\begin{algorithmic} % The number tells where the line numbering should start
		\State \textbf{Construct} the grammar $G_0$ for the initial problem
		\State \textbf{Initialize} the population $P_0$ based on $G_0$
		\State \textbf{Evaluate} $P_0$ on the initial problem with respect to $t$ and $\rho$
		\For{$i := 0, \dots, n-1$}
		\If{$i > 0$ and $i \mod m = 0$}
		\State $j := i / m$ 
		\State Increase the problem size
		\State \textbf{Construct} the corresponding grammar $G_j$
		\State  \textbf{Adapt} the current population $P_i$ to $G_j$
		\State \textbf{Evaluate} $P_i$ on the new problem with respect to $t$ and $\rho$
		\EndIf
		\State \textbf{Generate} new solutions $C_i$ based on $P_i$ and $G_j$
		\State \textbf{Evaluate} $C_i$ on the current problem with respect to $t$ and $\rho$
		\State \textbf{Select} $P_{i+1}$ from $C_i \cup P_i$
		\EndFor
		\State \textbf{Construct} the grammar $G$ for the target problem
		\State  \textbf{Adapt} the current population $P_n$ to $G$
		\State \textbf{Identify the best solver} by evaluating $P_{n}$ on the target problem
	\end{algorithmic}
\end{algorithm}
The first step of this procedure is the choice of an initial problem size, which should be small enough to enable the fast evaluation of a large number of randomly generated and thus often inefficient solvers.
As the search progresses and the average quality of the individuals in the population improves, the problem size can then be iteratively increased toward the target size.
While each problem size adaption increases the required time to evaluate each solver, it also improves the accuracy of evaluation with respect to both objectives.
As discussed in Section~\ref{sec:generalization:objective-function-definition}, evaluating a multigrid-based solver on a sequence of increasingly larger instances of the same problem allows us to assess whether the choice of the grid spacing $h$ affects its convergence.
Also, note that if there is only a small difference between the execution times of two non-dominating solvers, even slight hardware-based fluctuations in the measurements might perturb the outcome of an evaluation.
Considering a larger instance of the same problem reduces the relative magnitude of these fluctuations compared to the overall evaluation time.
At the end of Algorithm~\ref{alg:generalization-procedure}, we obtain a population that has evolved against a sequence of problem instances that iteratively approaches the size of the target instance.
We, therefore, identify the fastest solver by only considering those individuals contained in the first non-dominated front of this population, i.e., the subset in which none of the individuals is dominated by any of those present in the population.

Finally, note that so far, we have only considered increasing the problem size while evolving the population.
However, in certain cases, a PDE contains additional parameters which need to be adapted accordingly.
One prominent example that we consider in this thesis is the indefinite Helmholtz equation, as given by
\begin{equation}
	-(\nabla^{2} + k^{2})u = f,
\end{equation}
where $\nabla^{2}$ is the Laplace operator, $k$ the \emph{wavenumber} and $f$ the source term.
In general, the difficulty of solving this problem increases with the value of $k$.
However, many applications require the discretization width $h$ to fulfill an accuracy requirement, such as $h k \leq 0.625$. 
As a consequence, in order to solve this problem on a coarser grid, we also need to adapt the wavenumber accordingly, which results in a sequence of problem instances not only increasing in size but also in difficulty.
In Chapter~\ref{chapter:experiments}, we will demonstrate that our generalization procedure can cope with this challenge, yielding efficient multigrid methods for Helmholtz problems of varying size and difficulty.

\subsection{Implementation}
After we have now both motivated and described a procedure for the grammar-based design of generalizable multigrid methods, the remaining step is its successful implementation within the EvoStencils framework.
First of all, note that the individual evolutionary operators, i.e., initialization, mutation, crossover, and selection, are all implemented based on the created \emph{PrimitiveSetTyped} object. 
Their application is thus independent of the underlying problem size, and we only have to attach each operator to the respective \emph{Toolbox} object, as shown in Listing~\ref{code:gp:toolbox}.
We can generate a grammar for grid hierarchies with varying step size $h$ but the same number of coarsening steps by utilizing the \emph{generate\_grammar} function defined in Listing~\ref{code:grammar:generate-grammar}.
For this purpose, we only need to provide a different value for the argument \emph{max\_level}.
However, an essential issue that has not been addressed yet is how we can adapt the current population to a new grammar.
For this purpose, we need to return to the original formulation of our multigrid grammar, whose productions are shown in Algorithm~\ref{table:multigrid-grammar}.
Note that the level of each variable and terminal, unless it is level-independent, is denoted by its subscript.
Each of these terms is an expression whose value depends on $h$, i.e., the spacing of the finest grid.
In other words, if we want to apply a multigrid method whose derivation tree has been generated based on a discretization hierarchy with the step size $h$ to a different one of similar depth but with a step size of $H$, we only have to replace each occurrence of $h$ with the value of $H$.
Now recall that in our implementation, each derivation tree is represented as a \emph{PrimitiveTree} object of DEAP's GP module, which internally stores a list of its nodes in depth-first order.
Listing~\ref{code:gp:primitive} contains a minimal implementation of the \emph{Primitive} and \emph{Terminal} class within DEAP.
\begin{listing}
	\inputminted{python}{evostencils/gp/primitive.py}
	\caption{Primitive and Terminal Class in DEAP}
	\label{code:gp:primitive}
\end{listing}
According to this implementation, each \emph{Primitive} and \emph{Terminal} object is identified by three attributes - its \emph{name}, argument types (\emph{args}), and return type (\emph{ret}).
Note that a \emph{Terminal} object does not possess any input types, and if the \emph{terminal} argument of its \emph{\_\_init\_\_} method is provided as a string, the \emph{terminal} and \emph{name} attributes are identical.
However, neither of the classes incorporates the necessary information for its compilation to executable Python code.
Therefore, in addition to the given \emph{PrimitiveTree}, the respective \emph{PrimitiveSetTyped} object needs to be provided, which then enables constructing a sequence of function applications according to the order of the tree nodes.  
As a consequence, in case two different \emph{PrimitiveSetTyped} objects are structurally equal and employ the same name string for each of their \emph{Primitive} and \emph{Terminal} objects, they enable the compilation of the same \emph{PrimitiveTree} objects.
Now note that we generate the \emph{name} of each \emph{Primitive} and \emph{Terminal} in Listing~\ref{code:grammar:add-level} and~\ref{code:grammar:add-terminals} using the same problem-independent naming convention.
Since the subscript included in each name specifies the current level within the discretization hierarchy only symbolically, each \emph{PrimitiveTree} generated based on a \emph{PrimitiveSetTyped} object returned by our \emph{generate\_grammar} function can be compiled by any other \emph{PrimitiveSetTyped} object that has been obtained using the same value for the \emph{depth} argument.
While this provides us with a way to compile a given \emph{PrimitiveTree} after replacing our previous \emph{PrimitiveSetTyped} object with a new one, we have not yet addressed the question of how this affects the generation of new individuals through mutation and crossover.
In the case of both operators, the creation of new individuals is subject to the type constraints specified within the \emph{Primitive} and \emph{Terminal} objects of the parent individuals.
Therefore, whenever a modification is to be applied at a specific position within a \emph{PrimitiveTree}, the types of the respective \emph{Primitive} and \emph{Terminal} objects need to match.
If we consider the initialization of each type in the respective method of the \emph{Types} class defined in Listing~\ref{code:grammar:types}, we can see that each \emph{Type} object is created as a function of the \emph{depth} argument.
It is independent of the details of the discretization hierarchy based on which a \emph{PrimitiveSetTyped} object is constructed.
Therefore, exchanging a \emph{PrimitiveSetTyped} with one of similar \emph{depth} does not affect the semantics of each \emph{Type} object, which means that the same mutation and crossover operators can be applied without further adaption.
We can conclude the previous discussion by stating that while each \emph{PrimitiveTree} contains the computational structure of the corresponding multigrid method, all required information for its interpretation with respect to a particular discretization hierarchy is contained in the supplied \emph{PrimitiveSetTyped} object.
Therefore, whenever we want to increase the problem size within our evolutionary program synthesis procedure, we only have to generate a new \emph{PrimitiveSetTyped} object based on which we then update all operations registered at the current \emph{Toolbox} object.
At the same time, all individuals in the population remain unchanged and only need to be reevaluated on the updated problem instance.
The resulting steps can then be implemented in the form of an additional method of the \emph{Optimizer} class, which is shown in Listing~\ref{code:optimization:adapt-problem-size}.
\begin{listing}
	\inputminted{python}{evostencils/optimization/adapt_problem_size.py}
	\caption{Optimizer Class -- Problem Size Adaption}
	\label{code:optimization:adapt-problem-size}
\end{listing}
This implementation leverages the \emph{initialize\_code\_generation} method of the provided \emph{CodeGenerator} object to adapt the respective ExaStencils configuration files according to the provided \emph{max\_level} argument, which defines the maximum level of the discretization hierarchy.
What now remains is the integration of this method into the implementation of our evolutionary algorithm defined in Listing~\ref{code:optimization:evolutionary_search}.
However, we postpone this step until we have described the next major extension of our basic implementation, which is the distributed parallelization of our approach using the message-passing interface (MPI).

\section{Distributed Parallelization}
\label{sec:distributed-parallelization}
As we have already discussed in Section~\ref{sec:search-space-estimation}, the size of the search space spanned by our family of grammars makes it infeasible to evaluate every single multigrid method that can be generated based on their productions.
Even though the utilization of search heuristics in the form of an evolutionary algorithm allows us to reduce the number of considered individuals significantly, we still have to execute a large number of solvers on different problem instances.
Furthermore, note that for the evaluation of each solver, we need to utilize the ExaStencils framework to automatically generate a C++ implementation, which then has to be compiled into an executable program.
Both steps induce a significant overhead and hence further increase the evaluation time.
A common approach to accelerate the computationally intensive parts of an evolutionary algorithm is to distribute their execution to several compute nodes such that each computational step can be performed in parallel.
An overview of different approaches for the distributed parallelization of evolutionary algorithms can be found in~\cite{gong2015distributed}.
In principle, we can distinguish between approaches that are behaviorally equivalent to a sequential evolutionary algorithm and those that do not fulfill this property, usually in order to achieve better scalability.
Unfortunately, which approach leads to the best outcome can not be answered in general.
Before deciding on a specific parallelization method, we hence first need to investigate which parts of our evolutionary search method have to be parallelized to achieve good scalability.

\subsection{Empirical Execution Time Analysis}
\label{sec:execution-time-analysis}
According to Algorithm~\ref{alg:genetic-programming}, each step of our evolutionary algorithm consists of the following four operations:
\begin{enumerate}
	\item Parent Selection
	\item Child Creation
	\item Child Evaluation
	\item Population Selection
\end{enumerate}
In order to estimate the expected speedup of a parallel implementation of each of these operations, we first determine their fraction of the algorithm's total execution time.
As a representative example, we consider Poisson's equation on the unit square $\left[0,1\right]^2$ with Dirichlet boundary conditions. 
We discretize this equation using a uniform grid with step size $h = 1/2^{11}$ and the common five-point stencil
\begin{equation*}
	\nabla^2_h = 
	\frac{1}{h^2} \begin{bmatrix}
		0 & 1 & 0\\
		1 & -4 & 1 \\
		0 & 1 & 0  
	\end{bmatrix},
\end{equation*} 
which leads to a system of linear equations with $4\,190\,209$ unknowns.
The complete specification of this test problem can be found in Section~\ref{sec:poisson-equation}.
In order to obtain representative measurements for each of the four steps of our evolutionary algorithm, we execute it in the form of the \emph{run} method defined in Listing~\ref{code:optimization:optimizer} for a total number of 250 generations on a single socket of the \emph{Meggie} compute cluster of the Erlangen National High-Performance Computing Center (NHR)\footnote{As an exception, the child evaluation step is performed in parallel on multiple sockets of the same type. Since the order of evaluation does not change the behavior of our algorithm, this decision does not affect the measurements.}.
Note that we do not apply the generalization procedure introduced in Section~\ref{sec:generalization} here, which means that the problem size is kept constant throughout the execution of our evolutionary algorithm.
In each generation, we select $\lambda = 256$ individuals from the current population, based on which we create $\lambda$ children.
A new population of $\mu = 256$ individuals is then obtained from the combined set of $512$ individuals using the NSGA-II non-dominated sorting procedure described in~\cite{deb2002fast}.
We measure the average time required for each of the four steps over all generations, which is shown in Table~\ref{table:evolutionary-search-profiling}.
\begin{table}
	\caption{Average time required for each step performed within one generation of the evolutionary algorithm.}
	\label{table:evolutionary-search-profiling}
	\centering
	\begin{tabular}{l c}
		\toprule
		Step & Average Time \\
		\midrule
		Parent Selection & 0.68 ms \\
		\midrule
		Child Creation  & 0.32 s \\
		\midrule
		Child Evaluation  & 3.31 h \\
		\midrule
		Population Selection  & 0.20 s \\
		\bottomrule
	\end{tabular}
\end{table}
According to these measurements, the overall execution time of our implementation is heavily dominated by the evaluation step, which is reflected in the fact that the combined execution times of all other steps do not even account for one percent of the overall time.
Consequently, we can drastically reduce the execution time of our implementation by performing the evaluation of multiple individuals in parallel, while the parallelization of any other step will only result in a negligible speedup. 
Since we have to evaluate at least a single individual per compute node, the maximum achievable speedup is equal to $\lambda$, i.e., the number of children created in each generation of our method.
Finally, we need to answer the question of whether the previous statements still hold when we apply our evolutionary program synthesis method to other PDE-based problems.
Therefore, note that the two-dimensional Poisson equation represents a common test problem that is well known to be efficiently solvable by multigrid.
In fact, Poisson's equation has motivated the development of multigrid methods by Fedorenko~\cite{fedorenko1962relaxation}, Brandt~\cite{brandt1977multi} et al., and hence these methods achieve the highest possible degree of efficiency in solving it.
For the majority of other PDE-based problems of similar size, we can expect a further increase in the execution time, which leads to an even larger relative time consumption of the evaluation step.
Therefore, we can safely assume that our observation for the given test problem can be safely carried over to other PDE-based problems of similar or greater size and difficulty.

\subsection{Parallelization Method}
Based on the previous discussion, we can now derive a suitable parallelization scheme for our evolutionary algorithm.
However, while we have already estimated the impact of parallel execution of each of its steps, we have not yet discussed how to parallelize its individual operations on a given number of processing units. 
In general, if each operation within a sequence of computations can be performed independently, which means that it is not affected by the result of any other operation, the sequence is trivially parallelizable.
As this condition is fulfilled for step~2--3 of our evolutionary algorithm, these operations can be performed in a fully parallel manner.
In contrast, in both selection steps of our method, each processing unit needs to access the complete population.
We can thus distinguish two fundamentally different ways to parallelize them on a multi-processor system:
\begin{enumerate}
	\item Duplicate the population on each processing unit.
	\item Split the population into subpopulations and perform the selection on each of them independently while allowing periodic migration between certain subpopulations. This approach is usually described with the term \emph{island-based} evolutionary algorithm.
\end{enumerate}   
The first approach achieves behavioral equivalence to a sequential evolutionary algorithm at the cost that both the memory and computational requirements increase with the population size $\mu$, which restricts its applicability to only medium-sized populations.
In contrast, depending on the amount of migration between the individual subpopulations, which require a certain amount of communication, island-based models can yield higher scalability since all operations are performed on completely independent subpopulations.
On the downside, an island-based approach comprises the risk of selecting a higher percentage of inferior individuals, as only individuals in the respective subpopulation are considered for selection, which might lead to slower convergence compared to its sequential counterpart.
Considering the relatively low cost of selection even compared to the evaluation of a single individual\footnote{If we divide the total evaluation time per generation in Table~\ref{table:evolutionary-search-profiling} by the number of children, we obtain an average evaluation time of 47 seconds per individual.}, we can conclude that a duplication of the whole population is feasible for most experiments performed on small to medium-sized compute clusters.
It is, therefore, the chosen method of parallelization within our implementation.
While this decision theoretically limits scalability, for all experiments considered in this thesis, which do not employ populations larger than 256 individuals, a duplication of the complete population is feasible.
However, an island-based parallelization can be considered a viable extension for potential future applications that require us to execute our algorithm with a significantly larger population.

\subsection{Implementation}
After deriving a suitable parallelization approach, we can now proceed with its implementation as an extension of our previously defined \emph{Optimizer} class shown in Listing~\ref{code:optimization:optimizer}.
For this purpose, we utilize the message-passing interface (MPI), which is available in the form of the Python package \emph{mpi4py}.
While MPI only defines interfaces for the C and Fortran programming languages, mpi4py provides an additional layer of abstractions that enables the exchange of arbitrary Python objects between different processes using Python's Pickle library.
As we have already discussed in Section~\ref{sec:evostencils-part1:productions}, Pickle provides a unified way to serialize and deserialize objects based on a portable binary format, which can then be transmitted using the core functionality provided by MPI.
Since MPI represents the de facto standard for distributed computing and is thus supported on the majority of high-performance computing systems, its usage facilitates the portability of our implementation.
Furthermore, the availability of highly-optimized MPI implementations, which are often developed in cooperation with hardware manufacturers, enables communication between different processors in a highly-efficient manner.
As a first step towards the parallelization of our evolutionary program synthesis method with mpi4py, we extend the previously defined \emph{Optimizer} class found in Listing~\ref{code:optimization:optimizer-mpi} by providing an interface to all required MPI operations. 
\begin{listing}
	\inputminted[linenos]{python}{evostencils/optimization/optimizer_mpi.py}
	\caption{Optimizer Class -- MPI Extension}
	\label{code:optimization:optimizer-mpi}
\end{listing}
For this purpose, we add the MPI communicator object, the number of processes, and the process rank as additional arguments to the initialization method.
Note that all MPI operations can then be performed solely based on this information and the respective communicator object.
In order to exchange individuals between the processes, we utilize the \emph{allgather} operation, which first collects a list of objects from all processes that are then distributed to each individual process.
As in our case, each of these objects corresponds to a list of individuals, we additionally employ the \emph{merge\_lists} function to merge all sublists into a single list, which then contains the complete set of individuals collected from all processes.
Note that in case only a single process exists, we simply return the passed object without modification, which results in a unified interface for the sequential and parallel execution of our evolutionary algorithm.
The resulting operation is then implemented in Lines~15--19 of Listing~\ref{code:optimization:optimizer-mpi}. 

As a final step, we can now utilize this interface to implement a parallel version of the generalization procedure described in Algorithm~\ref{alg:generalization-procedure} as an extension of the basic implementation of our evolutionary algorithm.
The resulting Python implementation is shown in Listing~\ref{code:optimization:evolutionary-search-mpi}.
\begin{listing}
	\inputminted[linenos]{python}{evostencils/optimization/evolutionary_search_mpi.py}
	\caption{Evolutionary Search Method with Generalization and Parallelization}
	\label{code:optimization:evolutionary-search-mpi}
\end{listing}
Since most of the required functionality is already implemented within the \emph{adapt\_problem\_size} and \emph{allgather} methods, only a few adaptions of our original implementation are required.
First of all, we include an additional argument \emph{generalization\_interval}, which corresponds to the parameter $m$ in Algorithm~\ref{alg:generalization-procedure}.
Based on the value of this argument, we iteratively increase the problem size after a specified number of generations, which is implemented in line~15--21.
Finally, we parallelize the individual steps of our evolutionary algorithm using the previously defined MPI interface.
According to the MPI programming model, if the number of processes is larger than one, each process executes its own instance of the same program.
We thus only have to implement the required synchronization points between the processes.
Similar to our original implementation, the first step within our evolutionary program synthesis method is the generation and evaluation of an initial population.
In line~6--9, each process first generates and evaluates its respective fraction of the initial population, which is then combined and distributed using the \emph{allgather} method in line~10.
In a similar fashion, each process generates its fraction of the offspring by first selecting the respective number of parents in line~28, based on which new individuals are created in line~30 using crossover and mutation.
Again, after each process has finished the evaluation of its local individuals, they are combined using the \emph{allgather} method in line~34.
Since after this operation, each process has an exact copy of all newly created individuals, the subsequent elitist selection in line~37 consistently yields the same population, based on which the algorithm proceeds until the maximum number of generations has been reached.
With the implementation of a scalable evolutionary program synthesis method that can leverage the compute capabilities of current multi-node systems, we can now evaluate the effectiveness of our approach for the grammar-based design of multigrid methods in a number of experiments, where we consider two common PDE-based model problems, Poisson's equation, and a linear elastic boundary value problem.
As a final evaluation step, we then assess the efficiency and generalizability of the multigrid methods obtained with the generalization procedure described in Algorithm~\ref{alg:generalization-procedure} on a difficult benchmark problem, the indefinite Helmholtz equation with large wavenumbers.

% TODO Maybe include this section again
%\section{Systems of Partial Differential Equations}