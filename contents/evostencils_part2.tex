\section{Generalization}
The first crucial extension of our grammar-based evolutionary search method is the systematic generalization of an evolved population of multigrid methods to different instances of a PDE. 
As we have already briefly mentioned in Section~\ref{sec:fitness-evaluation-and-selection}, if properly constructed, the convergence of a multigrid method is independent of the discretization width $h$, which is usually described with the term $h$-independent convergence.
Therefore, the same method can often be successfully applied to different systems that arise from similar discretizations of the same PDE.
In Section~\ref{sec:fitness-evaluation-and-selection}, we have already introduced the idea of evaluating each multigrid solver on a number of proxy problems that possess similar properties as the problem that we are actually interested to solve.
The motivation for this idea is that, while we are usually interested in solving a problem instance of specific size, the evaluation of each solver on this instance requires too many computational resources.
As a remedy, in many cases, it is possible to construct such a set of proxy problems, by discretizing the same PDE on the given domain with a varying step size $h$.
The consequence of the $h$-independent convergence of multigrid method is that, if a functioning multigrid solver is available, it is expected to solve the problem using the same minimum number of operations per grid point.
However, as in practice, we usually do not know what the minimum number of operations per grid point is, we are instead interested in finding the multigrid method that leads to the fastest solving time $T_\varepsilon$ for the target problem with a discretization width of $h$.
The main challenge to achieve generalizations is then to identify this method among the set of candidates found within the search whereby we evaluate each candidate exclusively on instances of the same problem with a discretization width $H > h$ and, thus, smaller size.
Note that, since evolutionary algorithms are usually not guaranteed to find the global optimum, we restrict ourselves to identifying the optimum within the space of individuals sampled throughout the search.
First of all, recall that our evolutionary algorithm, whose implementation is shown in Listing~\ref{code:optimization:evolutionary_search}, performs a search by evolving a population of individuals for a specified number of generations.
In each generation, new individuals are created, by means of mutation and crossover.
However, only a limited number of individuals, chosen from the combined set of child and parent individuals, are allowed to enter the new population.
Whether an individuals is accepted for the next generation within this process solely depends on its fitness, as defined by one or multiple optimization objectives.
To achieve generalization, it is, therefore, crucial that we define the fitness of an individual in a way that maximizes the probability that the optimum, according to our criterion $T_{\varepsilon}$, is contained in the final population.
On the downside, this means that we have to prevent this individual from getting evicted from the population at any point within the search.
As we have shown in Section~\ref{sec:fitness-evaluation-and-selection} the solving time $T_{\varepsilon}$ is given by the formula
\begin{equation*}
	T_{\varepsilon} = t \cdot \frac{\ln \varepsilon}{\ln \rho},
\end{equation*}
where $t$ is the execution time per iteration and $\rho$ the (asymptotic) convergence factor of the solver.
Therefore, based on this formulate, there are two ways to define the fitness of an individual:
\begin{enumerate}
	\item Single-objective: $T_{\varepsilon}$
	\item Multi-objective:  $t$ and $\rho$
\end{enumerate}
The main difference between these two formulations is that while a single-objective evaluation always returns a single individual as the optimum, a multi-objective evaluation instead identifies a set of Pareto-optimal individual, i.e. those individuals which do not \emph{dominate} each other.
Hereby, domination is defined as the ability to achieve a better value in both objectives.
Consequently, since in the given case an improvement in each of the two objectives, $t$ and $\rho$, necessarily also leads to a faster solving time $T_{\varepsilon}$, the single-objective optimum is always contained in the Pareto-front obtained from a multi-objective evaluation of the same individuals.

The important question regarding generalization now is, whether the individual with the fastest solving time $T_{\varepsilon}$ will also be consistently selected as an optimum based on its evaluation on each problem instance considered within the search.
Here first the question arises whether the solving time $T_{\varepsilon}$, as a single-objective, leads to the same ordering of individual for each problem instance.
While in case of $h$-independent convergence, the convergence factor $\rho$ is expected to be constant, the execution time per iteration $t$ is drastically affected by hardware effects.
For instance, in case the memory requirement for a certain problem size exceeds the capacity of the cache, the execution time is expected to increase substantially compared to a problem instances that still fits into the cache\footnote{Note that this is only true for memory-bound computations. A property that is, however, fulfilled for the majority of stencil operations.}.
As a consequence, the execution time per iteration of a multigrid method that achieves the fastest solving time for a small problem might drastically increase for a larger problem instance, which means that the solver might no longer be optimal for that problem size.
On the downside, if we consider the solver that achieves the fastest solving time for a certain problem instance.
While this method might no longer be optimal with respect to its solving time for problems of smaller size, there is a high probability that it is still contained in the Pareto-front obtained through a multi-objective evaluation.
In general, faster convergence is either achieved by applying a higher number of smoothing or coarse-grid correction steps.

Now consider the following example of two different non-dominating multigrid V-cycles.
The first one achieves a convergence factor of $0.15$ and an execution time per iteration of one millisecond using a total number of two smoothing steps per level on a grid with step size $h$, while the other one achieves a convergence factor of $0.1$ and an execution time of 1.5 milliseconds using three smoothing steps per level.
If we now consider both methods on a smaller grid with step size $2h$, it is very unlikely that the first method achieves a faster convergence than the second one.
On the other hand, three smoothing steps per level will also lead to a larger execution time per iteration for a smaller problem.
As a consequence, the dominance relation between both methods is preserved.
In contrast, assuming that the second method achieves a slightly faster solving time on the larger grid, it is impossible to predict whether this is still the case for a smaller grid.  
While considering the search for a generalizable multigrid method as a multi-objective optimization problem increases the probability that the final population contains the method with the fastest solving time for our target problem instance, this approach still has certain limitations.
If we consider different choices for each smoothing and coarse-grid correction, our assumption that a certain sequence of operations also leads to a faster execution time for a smaller problem is no longer true for each case, as certain operations might have a lower complexity and, thus, might lead to a smaller decrease in the execution time on a smaller grid.
One possibility, that has been already mentioned in Section~\ref{sec:fitness-evaluation-and-selection}, is to overcome these limitations by incorporating performance models into the evaluation, which allow to obtain a prediction for a method's execution time on a larger grid.
However, as in this thesis we only consider operations whose complexity is independent of the grid size on which they are applied, the execution time per iteration measured on a certain grid size provides a sufficient prediction for its value on a larger grid.

Based on these observations, we can now formulate an evolutionary search method for the systematic generalization of multigrid methods to a given problem class, which is summarized in Algorithm~\ref{alg:generalization-procedure}.
\begin{algorithm}
	\caption{Generalization Procedure}
	\label{alg:generalization-procedure}
	\begin{algorithmic}[1] % The number tells where the line numbering should start
		\State \textbf{Construct} the grammar $G_0$ for the initial problem
		\State \textbf{Initialize} the population $P_0$ based on $G_0$
		\State \textbf{Evaluate} $P_0$ on the initial problem with respect to $t$ and $\rho$
		\For{$i := 0, \dots, n-1$}
		\If{$i > 0$ and $i \mod m = 0$}
		\State $j := i / m$ 
		\State Increase the problem size
		\State \textbf{Construct} the corresponding grammar $G_j$
		\State  \textbf{Adapt} the current population $P_i$ to $G_j$
		\State \textbf{Evaluate} $P_i$ on the new problem with respect to $t$ and $\rho$
		\EndIf
		\State \textbf{Generate} new solutions $C_i$ based on $P_i$ and $G_j$
		\State \textbf{Evaluate} $C_i$ on the current problem with respect to $t$ and $\rho$
		\State \textbf{Select} $P_{i+1}$ from $C_i \cup P_i$
		\EndFor
		\State \textbf{Construct} the grammar $G$ for the target problem
		\State  \textbf{Adapt} the current population $P_n$ to $G$
		\State \textbf{Identify the best solver} by evaluating $P_{n}$ on the target problem
	\end{algorithmic}
\end{algorithm}
Within this procedure, the search is initiated by choosing an initial problem size.
Since at the beginning, the majority of the individuals in the population, which are generated through random initialization, are expected to represent inefficient multigrid methods, the choice of a small problem size enables the fast evaluation of a large number of individuals.
However, as the search progresses and the average quality of the individuals in the population improves, the problem size can then be iteratively increased towards the target size.
While each problem size adaption increases the required time to evaluate each method found within the search, it also increases the accuracy of evaluation with respect to both objectives.
In particular, we can only reliably test the $h$-independent convergence of a given method by evaluating it on a sequence of increasingly-larger instances of the same problem.
Furthermore, as the difference between the execution times per iteration of different non-dominating solvers decreases, even slight hardware-based fluctuations in the measurements might perturb the outcome of an evaluation.
This effect can again be reduced by considering a larger instance of the same problem, as, consequently, the relative magnitude of these fluctuations decreases compared to the overall evaluation time.
At the end of Algorithm~\ref{alg:generalization-procedure} we then obtain a population that contains a set of non-dominated individuals according to the largest problem size considered within the search.
Therefore, as discussed above, we can identify the fastest solver for our target problem instance, by only considering those individuals contained in the first non-dominated front, i.e. the population subset in which none of the individuals is dominated by any of those encountered within the search.

Finally, note that so far we have only considered increasing the problem size within the search.
However, in certain cases, a PDE contains additional parameters, which need to be adapted accordingly.
One prominent example, which we consider in this work is the indefinite Helmholtz equation, as given by
\begin{equation}
	-(\nabla^{2} + k^{2})u = f,
	\label{eq:helmholtz}
\end{equation}
where $\nabla^{2}$ is the Laplace operator, $k$ the \emph{wavenumber} and $f$ the source term.
In general, the difficulty for solving this problem increases with the value of the wavenumber $k$ .
However, many applications, for instance, require the discretization width $h$ to fulfill an accuracy requirement of $h k \leq 0.625$. 
As a consequence, in order to solve this problem on a smaller grid, we also need to adapt the wavenumber accordingly, which results in a sequence of problem instances that do not only increase in size but also in difficulty.
In Chapter~\ref{chapter:experiments}, we will then demonstrate that our generalization procedure is capable of evolving efficient multigrid methods for Helmholtz problems of varying size and difficulty.

\subsection{Implementation}
After we have now both motivated and formally described a procedure for the grammar-based evolution of generalizazible multigrid methods, the remaining step represents its successful implementation within the EvoStencils framework, as described in the last chapter.
First of all, note that the individual evolutionary operations performed within the search, i.e. initialization, mutation, crossover and selection, are all a function of the created primitive set, which means that they can be utilized in a similar way independent of the underlying problem size by registering them to the respective \emph{Toolbox} object, as shown in Listing~\ref{code:gp:toolbox}.
Furthermore, we can easily generate a grammar for different problem sizes but with a discretization hierarchy of similar depth by utilizing the \emph{generate\_grammar} function, as shown in Listing~\ref{code:grammar:generate-grammar}, while providing a different value for the argument \emph{max\_level}.
However, the essential question that has not been answered yet is how we adapt the current population to the new grammar which has been generated by increasing the problem size, as it is formulated in Line 9 of Algorithm~\ref{alg:generalization-procedure}.
To address this issue, we need to return to the original formulation of our multigrid grammar, as shown in Table~\ref{table:multigrid-grammar}.
Here note that while the level of each variable and certain terminal symbols is denoted by its subscript, each of these terms is an expression whose value depends on the discretization width $h$ on the finest level.
In other words, if we want to apply a multigrid method whose derivation tree has been generated based on a discretization hierarchy with step size $h$ and fixed depth to a different hierarchy of similar depth but with a step size of $H$, we only have to substitute the value of both step sizes in each subscript.
Now recall that in our implementation each derivation tree is represented by a \emph{PrimitiveTree} object of DEAP's GP module, which internally stores a list of each of its nodes in depth-first order.
Listing~\ref{code:gp:primitive} shows a reduced implementation of the \emph{Primitive} and \emph{Terminal} class within DEAP.
\begin{listing}
	\inputminted[linenos]{python}{evostencils/gp/primitive.py}
	\caption{GP: Primitive and Terminal class}
	\label{code:gp:primitive}
\end{listing}
The important insight that we gain from this implementation is that each \emph{Primitive} and \emph{Terminal} object is identified by the three attributes, its input types, return type and name, whereby the latter does not possess any input types.\footnote{Note that if the second argument for the initialization of a \emph{Terminal} object is provided as a string, the \emph{terminal} and \emph{name} attributes are identical.}
Therefore, a \emph{PrimitiveTree} does not contain the complete information required for its compilation to executable Python code, but instead in addition we need to provide the respective \emph{PrimitiveSetTyped}, which then allows to construct a sequence of function applications according to the order of primitives and terminals within the tree.  
As a consequence, in case two different \emph{PrimitiveSetTyped} objects are structurally equal and employ the same name string for each of their primitives and terminals, both can be used to compile the same \emph{PrimitiveTree} object.
Now note that in Listing~\ref{code:grammar:add-terminals}, and ~\ref{code:grammar:add-level}, we generate the name string for each \emph{Primitive} and \emph{Terminal} using the problem-independent naming convention together with a subscript that corresponds to its depth in the discretization hierarchy.
As the latter is independent of the actual discretization width, each \emph{PrimitiveTree} generated based on a \emph{PrimitiveSetTyped} object returned by our \emph{generate\_grammar} function can be compiled with any other of those constructed with this function using the same value for the \emph{depth} argument\footnote{Note that the structural equality of both objects also requires us to provide the same value for the \emph{samples} argument}.
However, while we answered the questions whether we can compile a given \emph{PrimitiveTree} using a structurally-equal but different primitive set, we have not addressed the issue of generating new individuals based on existing ones using the previously defined mutation and crossover operators.
In case of both operators, the construction of new individuals is subject to the type constraints defined within each of its \emph{Primitive} and \emph{Terminal} object.
Therefore, if we aim to construct new individuals based existing ones, that have been generated using a different \emph{PrimitiveSetTyped} object, the types of each \emph{Terminal} and \emph{Primitive} object need to match.
However, if we consider the initialization of each type in the respective method of the \emph{Types} class, as shown in Listing~\ref{code:grammar:types}, we can see that this condition is fulfilled, as all types are created as a function of the \emph{depth} argument and are, hence, independent of the details of the discretization hierarchy based on which the respective primitive set is constructed.
We can, therefore, summarize the previous discussion with the observation that while each individual contains the computational structure of the corresponding multigrid method, all required information to apply this individual to a certain discretization hierarchy is contained in the respective \emph{PrimitiveSetTyped} object.

 
 
 




\section{Distributed Parallelization}
\section{Systems of Partial Differential Equations}