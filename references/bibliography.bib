
@inproceedings{amdahl1967validity,
	title={Validity of the single processor approach to achieving large scale computing capabilities},
	author={Amdahl, Gene M.},
	booktitle={Proceedings of the April 18-20, 1967, spring joint computer conference},
	pages={483--485},
	year={1967}
}

@book{ames2014numerical,
  title={Numerical methods for partial differential equations},
  author={Ames, William F},
  year={2014},
  publisher={Academic press}
}


@InCollection{	  antoine2016integral,
  title		= {{Integral Equations and Iterative Schemes for Acoustic
		  Scattering Problems}},
  author	= {Antoine, Xavier and Darbas, Marion},
  url		= {https://hal.archives-ouvertes.fr/hal-00591456},
  booktitle	= {{Numerical Methods for Acoustics Problems}},
  editor	= {F. Magoul{\`e}s},
  publisher	= {{Saxe-Coburg Editors}},
  year		= {2016},
  keywords	= {well-conditioned integral equation ; integral equation ;
		  high-frequency ; acoustic scattering ; preconditioners ;
		  GMRES ; Krylov solver},
  pdf		= {https://hal.archives-ouvertes.fr/hal-00591456/file/chapterVersionFinale.pdf},
  hal_id	= {hal-00591456},
  hal_version	= {v1}
}

@Book{		  back1997handbook,
  author	= {Back, Thomas and Fogel, David B. and Michalewicz,
		  Zbigniew},
  title		= {Handbook of Evolutionary Computation},
  year		= {1997},
  isbn		= {0750303921},
  publisher	= {IOP Publishing Ltd.},
  address	= {GBR},
  edition	= {first}
}

@article{bathe2007finite,
	title={Finite element method},
	author={Bathe, Klaus-J{\"u}rgen},
	journal={Wiley encyclopedia of computer science and engineering},
	pages={1--12},
	year={2007},
	publisher={Wiley Online Library}
}

@Article{	  benzi2002preconditioning,
  title		= {Preconditioning Techniques for Large Linear Systems: A
		  Survey},
  journal	= {Journal of Computational Physics},
  volume	= {182},
  number	= {2},
  pages		= {418-477},
  year		= {2002},
  issn		= {0021-9991},
  doi		= {https://doi.org/10.1006/jcph.2002.7176},
  url		= {https://www.sciencedirect.com/science/article/pii/S0021999102971767},
  author	= {Michele Benzi},
  abstract	= {This article surveys preconditioning techniques for the
		  iterative solution of large linear systems, with a focus on
		  algebraic methods suitable for general sparse matrices.
		  Covered topics include progress in incomplete factorization
		  methods, sparse approximate inverses, reorderings,
		  parallelization issues, and block and multilevel
		  extensions. Some of the challenges ahead are also
		  discussed. An extensive bibliography completes the paper.}
}

@Article{	  benzi2005numerical,
  title		= {Numerical solution of saddle point problems},
  volume	= {14},
  doi		= {10.1017/S0962492904000212},
  journal	= {Acta Numerica},
  publisher	= {Cambridge University Press},
  author	= {Benzi, Michele and Golub, Gene H. and Liesen, Jörg},
  year		= {2005},
  pages		= {1–137}
}

@Article{	  beyer2002evolution,
  title		= {Evolution strategies - A comprehensive introduction},
  author	= {Beyer, Hans-Georg and Schwefel, Hans-Paul},
  journal	= {Natural computing},
  volume	= {1},
  number	= {1},
  pages		= {3--52},
  year		= {2002},
  publisher	= {Springer-Verlag}
}

@InProceedings{	  billette20052004,
  author	= "Billette, F. J. and Brandsberg-Dahl, S.",
  title		= "The 2004 BP Velocity Benchmark",
  journal	= "",
  year		= "2005",
  volume	= "",
  number	= "",
  pages		= "",
  doi		= "https://doi.org/10.3997/2214-4609-pdb.1.B035",
  url		= "https://www.earthdoc.org/content/papers/10.3997/2214-4609-pdb.1.B035",
  publisher	= "European Association of Geoscientists and Engineers",
  issn		= "2214-4609",
  type		= "",
  eid		= "cp-1-00513"
}

@Article{	  bolten2018fourier,
  author	= {Bolten, Matthias and Rittich, Hannah},
  title		= {Fourier Analysis of Periodic Stencils in Multigrid
		  Methods},
  journal	= {SIAM Journal on Scientific Computing},
  volume	= {40},
  number	= {3},
  pages		= {A1642-A1668},
  year		= {2018},
  doi		= {10.1137/16M1073959},
  url		= { https://doi.org/10.1137/16M1073959 }
}

@Book{		  brameier2007linear,
  title		= {Linear genetic programming},
  author	= {Brameier, Markus and Banzhaf, Wolfgang and Banzhaf,
		  Wolfgang},
  volume	= {1},
  year		= {2007},
  publisher	= {Springer}
}

@Article{	  brandt1977multi,
  title		= {Multi-level adaptive solutions to boundary-value
		  problems},
  author	= {Brandt, Achi},
  journal	= {Mathematics of computation},
  volume	= {31},
  number	= {138},
  pages		= {333--390},
  year		= {1977}
}

@Book{		  briggs2000multigrid,
  author	= {Briggs, William L. and Henson, Van Emden and McCormick,
		  Steve F.},
  title		= {A Multigrid Tutorial},
  publisher	= {Society for Industrial and Applied Mathematics},
  year		= {2000},
  doi		= {10.1137/1.9780898719505},
  address	= {},
  edition	= {Second},
  url		= {https://epubs.siam.org/doi/abs/10.1137/1.9780898719505}
}

@Article{	  brown2021tuning,
  author	= {Brown, Jed and He, Yunhui and MacLachlan, Scott and
		  Menickelly, Matt and Wild, Stefan M.},
  title		= {Tuning Multigrid Methods with Robust Optimization and
		  Local Fourier Analysis},
  journal	= {SIAM Journal on Scientific Computing},
  volume	= {43},
  number	= {1},
  pages		= {A109-A138},
  year		= {2021},
  doi		= {10.1137/19M1308669},
  url		= { https://doi.org/10.1137/19M1308669 }
}

@Article{	  cocquet2017shift,
  author	= {Cocquet, Pierre-Henri and Gander, Martin J.},
  title		= {How Large a Shift is Needed in the Shifted Helmholtz
		  Preconditioner for its Effective Inversion by Multigrid?},
  journal	= {SIAM Journal on Scientific Computing},
  volume	= {39},
  number	= {2},
  pages		= {A438-A478},
  year		= {2017},
  doi		= {10.1137/15M102085X},
  url		= { https://doi.org/10.1137/15M102085X }
}

@Book{		  coello2007evolutionary,
  title		= {Evolutionary Algorithms for Solving Multi-Objective
		  Problems},
  author	= {Coello, Carlos A. Coello and Lamont, Gary B. and Van
		  Veldhuizen, David A. and others},
  volume	= {5},
  year		= {2007},
  publisher	= {Springer-Verlag}
}

@Article{	  cools2013analysis,
  author	= {Cools, Siegfried and Vanroose, Wim},
  title		= {Local Fourier analysis of the complex shifted Laplacian
		  preconditioner for Helmholtz problems},
  journal	= {Numerical Linear Algebra with Applications},
  volume	= {20},
  number	= {4},
  pages		= {575-597},
  keywords	= {Helmholtz equation, indefinite systems, high wavenumber,
		  Krylov method, shifted Laplacian preconditioner, local
		  Fourier analysis},
  doi		= {https://doi.org/10.1002/nla.1881},
  abstract	= {SUMMARYIn this paper, we solve the Helmholtz equation with
		  multigrid preconditioned Krylov subspace methods. The class
		  of shifted Laplacian preconditioners is known to
		  significantly speed up Krylov convergence. However, these
		  preconditioners have a parameter , a measure of the complex
		  shift. Because of contradictory requirements for the
		  multigrid and Krylov convergence, the choice of this shift
		  parameter can be a bottleneck in applying the method. In
		  this paper, we propose a wavenumber-dependent minimal
		  complex shift parameter, which is predicted by a rigorous
		  k-grid local Fourier analysis (LFA) of the multigrid
		  scheme. We claim that, given any (regionally constant)
		  wavenumber, this minimal complex shift parameter provides
		  the reader with a parameter choice that leads to efficient
		  Krylov convergence. Numerical experiments in one and two
		  spatial dimensions validate the theoretical results. It
		  appears that the proposed complex shift is both the minimal
		  requirement for a multigrid V-cycle to converge and being
		  near optimal in terms of Krylov iteration count. Copyright
		  © 2013 John Wiley \& Sons, Ltd.},
  year		= {2013}
}

@Article{	  couchet2007crossover,
  author	= {Couchet, Jorge and Manrique, Daniel and R{\'i}os, Juan and
		  Rodr{\'i}guez-Pat{\'o}n, Alfonso},
  title		= {Crossover and mutation operators for grammar-guided
		  genetic programming},
  journal	= {Soft Computing},
  year		= {2007},
  month		= {Aug},
  day		= {01},
  volume	= {11},
  number	= {10},
  pages		= {943-955},
  abstract	= {This paper proposes a new grammar-guided genetic
		  programming (GGGP) system by introducing two original
		  genetic operators: crossover and mutation, which most
		  influence the evolution process. The first, the so-called
		  grammar-based crossover operator, strikes a good balance
		  between search space exploration and exploitation
		  capabilities and, therefore, enhances GGGP system
		  performance. And the second is a grammar-based mutation
		  operator, based on the crossover, which has been designed
		  to generate individuals that match the syntactical
		  constraints of the context-free grammar that defines the
		  programs to be handled. The use of these operators together
		  in the same GGGP system assures a higher convergence speed
		  and less likelihood of getting trapped in local optima than
		  other related approaches. These features are shown
		  throughout the comparison of the results achieved by the
		  proposed system with other important crossover and mutation
		  methods in two experiments: a laboratory problem and the
		  real-world task of breast cancer prognosis.},
  issn		= {1433-7479},
  doi		= {10.1007/s00500-006-0144-9},
  url		= {https://doi.org/10.1007/s00500-006-0144-9}
}

@Article{	  criado2020grammatically,
  author	= {Ramos Criado, Pablo and Barrios Rolan{\'i}a, D. and
		  Manrique, Daniel and Serrano, Emilio},
  title		= {Grammatically uniform population initialization for
		  grammar-guided genetic programming},
  journal	= {Soft Computing},
  year		= {2020},
  month		= {Aug},
  day		= {01},
  volume	= {24},
  number	= {15},
  pages		= {11265-11282},
  abstract	= {The initial population distribution is an essential issue
		  in evolutionary computation performance. Population
		  initialization methods for grammar-guided genetic
		  programming have some difficulties generating a
		  representative sample of the search space, which negatively
		  affects the overall evolutionary process. This paper
		  presents a grammatically uniform population initialization
		  method to address this issue by improving the initial
		  population uniformity: the equiprobability of obtaining any
		  individual of the search space defined by the context-free
		  grammar. The proposed initialization method assigns and
		  updates probabilities dynamically to the production rules
		  of the grammar to pursue uniformity and includes a code
		  bloat control mechanism. We have conducted empirical
		  experiments to compare the proposed algorithm with a
		  standard initialization approach very often used in
		  grammar-guided genetic programming. The results report that
		  the proposed initialization method approximates very well a
		  uniform distribution of the individuals in the search
		  space. Moreover, the overall evolutionary process that
		  takes place after the population initialization performs
		  better in terms of convergence speed and quality of the
		  final solutions achieved when the proposed method generates
		  the initial population than when the usual approach does.
		  The results also show that these performance differences
		  are more significant when the experiments involve large
		  search spaces.},
  issn		= {1433-7479},
  doi		= {10.1007/s00500-020-05061-w},
  url		= {https://doi.org/10.1007/s00500-020-05061-w}
}

@Article{	  dalcin2021mpi4py,
  title		= {Mpi4py: Status update after 12 years of development},
  author	= {Dalcin, Lisandro and Fang, Yao-Lung L},
  journal	= {Computing in Science \& Engineering},
  volume	= {23},
  number	= {4},
  pages		= {47--54},
  year		= {2021},
  publisher	= {IEEE}
}

@Article{	  deb2002fast,
  author	= {K. {Deb} and A. {Pratap} and S. {Agarwal} and T.
		  {Meyarivan}},
  journal	= {IEEE Transactions on Evolutionary Computation},
  title		= {A fast and elitist multiobjective genetic algorithm:
		  NSGA-II},
  year		= {2002},
  volume	= {6},
  number	= {2},
  pages		= {182-197},
  doi		= {10.1109/4235.996017}
}

@InCollection{	  deb2011multi,
  title		= {Multi-objective optimisation using evolutionary
		  algorithms: an introduction},
  author	= {Deb, Kalyanmoy},
  booktitle	= {Multi-objective evolutionary optimisation for product
		  design and manufacturing},
  pages		= {3--34},
  year		= {2011},
  publisher	= {Springer}
}

@Article{	  deb2013evolutionary,
  title		= {An evolutionary many-objective optimization algorithm
		  using reference-point-based nondominated sorting approach,
		  part I: solving problems with box constraints},
  author	= {Deb, Kalyanmoy and Jain, Himanshu},
  journal	= {IEEE transactions on evolutionary computation},
  volume	= {18},
  number	= {4},
  pages		= {577--601},
  year		= {2013},
  publisher	= {IEEE}
}

@InCollection{	  deb2015multi,
  title		= {Multi-objective evolutionary algorithms},
  author	= {Deb, Kalyanmoy},
  booktitle	= {Springer handbook of computational intelligence},
  pages		= {995--1015},
  year		= {2015},
  publisher	= {Springer}
}

@Article{	  demmel2007fast,
  title		= {Fast linear algebra is stable},
  author	= {Demmel, James and Dumitriu, Ioana and Holtz, Olga},
  journal	= {Numerische Mathematik},
  volume	= {108},
  number	= {1},
  pages		= {59--91},
  year		= {2007},
  publisher	= {Springer-Verlag},
  doi		= {10.1007/s00211-007-0114-x},
  url		= {https://doi.org/10.1007/s00211-007-0114-x}
}

@Article{	  erlangga2004preconditioner,
  title		= "On a class of preconditioners for solving the Helmholtz
		  equation",
  journal	= "Applied Numerical Mathematics",
  volume	= "50",
  number	= "3",
  pages		= "409 - 425",
  year		= "2004",
  issn		= "0168-9274",
  doi		= "https://doi.org/10.1016/j.apnum.2004.01.009",
  url		= "http://www.sciencedirect.com/science/article/pii/S0168927404000091",
  author	= "Y. A. Erlangga and C. Vuik and C. W. Oosterlee",
  keywords	= "Helmholtz equation, Krylov subspace, Preconditioner",
  abstract	= "In 1983, a preconditioner was proposed [J. Comput. Phys.
		  49 (1983) 443] based on the Laplace operator for solving
		  the discrete Helmholtz equation efficiently with CGNR. The
		  preconditioner is especially effective for low wavenumber
		  cases where the linear system is slightly indefinite. Laird
		  [Preconditioned iterative solution of the 2D Helmholtz
		  equation, First Year's Report, St. Hugh's College, Oxford,
		  2001] proposed a preconditioner where an extra term is
		  added to the Laplace operator. This term is similar to the
		  zeroth order term in the Helmholtz equation but with
		  reversed sign. In this paper, both approaches are further
		  generalized to a new class of preconditioners, the
		  so-called “shifted Laplace” preconditioners of the form
		  Δφ−αk2φ with α∈C. Numerical experiments for
		  various wavenumbers indicate the effectiveness of the
		  preconditioner. The preconditioner is evaluated in
		  combination with GMRES, Bi-CGSTAB, and CGNR."
}

@Article{	  erlangga2006comparison,
  title		= "Comparison of multigrid and incomplete LU shifted-Laplace
		  preconditioners for the inhomogeneous Helmholtz equation",
  journal	= "Applied Numerical Mathematics",
  volume	= "56",
  number	= "5",
  pages		= "648 - 666",
  year		= "2006",
  issn		= "0168-9274",
  doi		= "https://doi.org/10.1016/j.apnum.2005.04.039",
  url		= "http://www.sciencedirect.com/science/article/pii/S016892740500108X",
  author	= "Y.A. Erlangga and C. Vuik and C.W. Oosterlee",
  keywords	= "Helmholtz equation, Shifted-Laplace preconditioner, Krylov
		  subspace methods, Multigrid, ILU",
  abstract	= "Within the framework of shifted-Laplace preconditioners
		  [Y. A. Erlangga, C. Vuik, C. W. Oosterlee, On a class of
		  preconditioners for the Helmholtz equation, Appl. Numer.
		  Math. 50 (2004) 409–425] for the Helmholtz equation,
		  different methods for the approximation of the inverse of a
		  complex-valued Helmholtz operator are discussed. The
		  performance of the preconditioner for Helmholtz problems at
		  high wavenumbers in heterogeneous media is evaluated.
		  Comparison with other preconditioners from the literature
		  is also presented."
}

@Article{	  erlangga2006multigrid,
  author	= {Erlangga, Y. A. and Oosterlee, C. W. and Vuik, C.},
  title		= {A Novel Multigrid Based Preconditioner For Heterogeneous
		  Helmholtz Problems},
  journal	= {SIAM Journal on Scientific Computing},
  volume	= {27},
  number	= {4},
  pages		= {1471-1492},
  year		= {2006},
  doi		= {10.1137/040615195},
  url		= { https://doi.org/10.1137/040615195 }
}

@Article{	  erlangga2008advances,
  author	= {Erlangga, Yogi A.},
  title		= {Advances in Iterative Methods and Preconditioners for the
		  Helmholtz Equation},
  journal	= {Archives of Computational Methods in Engineering},
  year		= {2008},
  month		= {Mar},
  day		= {01},
  volume	= {15},
  number	= {1},
  pages		= {37-66},
  abstract	= {In this paper we survey the development of fast iterative
		  solvers aimed at solving 2D/3D Helmholtz problems. In the
		  first half of the paper, a survey on some recently
		  developed methods is given. The second half of the paper
		  focuses on the development of the shifted Laplacian
		  preconditioner used to accelerate the convergence of Krylov
		  subspace methods applied to the Helmholtz equation.
		  Numerical examples are given for some difficult problems,
		  which had not been solved iteratively before.},
  issn		= {1886-1784},
  doi		= {10.1007/s11831-007-9013-7},
  url		= {https://doi.org/10.1007/s11831-007-9013-7}
}

@Article{	  erlangga2008multilevel,
  title		= {On a multilevel Krylov method for the Helmholtz equation
		  preconditioned by shifted Laplacian},
  author	= {Erlangga, Yogi A. and Nabben, Reinhard},
  journal	= {Electronic Transactions on Numerical Analysis},
  volume	= {31},
  number	= {403-424},
  pages		= {3},
  year		= {2008},
  publisher	= {Institute of Computational Mathematics}
}

@InBook{	  ernst2012difficult,
  author	= "Ernst, O. G. and Gander, M. J.",
  editor	= "Graham, Ivan G. and Hou, Thomas Y. and Lakkis, Omar and
		  Scheichl, Robert",
  title		= "Why it is Difficult to Solve Helmholtz Problems with
		  Classical Iterative Methods",
  booktitle	= "Numerical Analysis of Multiscale Problems",
  year		= "2012",
  publisher	= "Springer Berlin Heidelberg",
  address	= "Berlin, Heidelberg",
  pages		= "325--363",
  abstract	= "In contrast to the positive definite Helmholtz equation,
		  the deceivingly similar looking indefinite Helmholtz
		  equation is difficult to solve using classical iterative
		  methods. Simply using a Krylov method is much less
		  effective, especially when the wave number in the Helmholtz
		  operator becomes large, and also algebraic preconditioners
		  such as incomplete LU factorizations do not remedy the
		  situation. Even more powerful preconditioners such as
		  classical domain decomposition and multigrid methods fail
		  to lead to a convergent method, and often behave
		  differently from their usual behavior for positive definite
		  problems. For example increasing the overlap in a classical
		  Schwarz method degrades its performance, as does increasing
		  the number of smoothing steps in multigrid. The purpose of
		  this review paper is to explain why classical iterative
		  methods fail to be effective for Helmholtz problems, and to
		  show different avenues that have been taken to address this
		  difficulty.",
  isbn		= "978-3-642-22061-6",
  doi		= "10.1007/978-3-642-22061-6_10",
  url		= "https://doi.org/10.1007/978-3-642-22061-6_10"
}

@book{evans2010partial,
	title={Partial differential equations},
	author={Evans, Lawrence C},
	volume={19},
	year={2010},
	publisher={American Mathematical Soc.}
}

@article{eymard2000finite,
	title={Finite volume methods},
	author={Eymard, Robert and Gallou{\"e}t, Thierry and Herbin, Rapha{\`e}le},
	journal={Handbook of numerical analysis},
	volume={7},
	pages={713--1018},
	year={2000},
	publisher={Elsevier}
}

@InProceedings{	  fanaskov2021neural,
  author	= {Fanaskov, Vladimir},
  booktitle	= {2021 International Joint Conference on Neural Networks
		  (IJCNN)},
  title		= {Neural Multigrid Architectures},
  year		= {2021},
  volume	= {},
  number	= {},
  pages		= {1-8},
  doi		= {10.1109/IJCNN52387.2021.9533736}
}

@InProceedings{	  fang2010review,
  title		= {A review of tournament selection in genetic programming},
  author	= {Fang, Yongsheng and Li, Jun},
  booktitle	= {International Symposium on Intelligence Computation and
		  Applications},
  pages		= {181--192},
  year		= {2010},
  organization	= {Springer}
}

@Article{	  fedorenko1962relaxation,
  title		= {A relaxation method for solving elliptic difference
		  equations},
  journal	= {USSR Computational Mathematics and Mathematical Physics},
  volume	= {1},
  number	= {4},
  pages		= {1092-1096},
  year		= {1962},
  issn		= {0041-5553},
  doi		= {10.1016/0041-5553(62)90031-9},
  author	= {Fedorenko, Radii Petrovich}
}

@incollection{folland2020introduction,
	title={Introduction to partial differential equations},
	author={Folland, Gerald B.},
	booktitle={Introduction to Partial Differential Equations},
	year={2020},
	publisher={Princeton university press}
}

@InProceedings{	  fortin2013generalizing,
  author	= {Fortin, F\'{e}lix-Antoine and Grenier, Simon and Parizeau,
		  Marc},
  title		= {Generalizing the Improved Run-Time Complexity Algorithm
		  for Non-Dominated Sorting},
  year		= {2013},
  isbn		= {9781450319638},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/2463372.2463454},
  doi		= {10.1145/2463372.2463454},
  abstract	= {This paper generalizes the "Improved Run-Time Complexity
		  Algorithm for Non-Dominated Sorting" by Jensen, removing
		  its limitation that no two solutions can share identical
		  values for any of the problem's objectives. This constraint
		  is especially limiting for discrete combinatorial problems,
		  but can also lead the Jensen algorithm to produce incorrect
		  results even for problems that appear to have a continuous
		  nature, but for which identical objective values are
		  nevertheless possible. Moreover, even when values are not
		  meant to be identical, the limited precision of floating
		  point numbers can sometimes make them equal anyway. Thus a
		  fast and correct algorithm is needed for the general case.
		  The paper shows that generalizing the Jensen algorithm can
		  be achieved without affecting its time complexity, and
		  experimental results are provided to demonstrate speedups
		  of up to two orders of magnitude for common problem sizes,
		  when compared with the correct baseline algorithm from
		  Deb.},
  booktitle	= {Proceedings of the 15th Annual Conference on Genetic and
		  Evolutionary Computation},
  pages		= {615–622},
  numpages	= {8},
  keywords	= {non-dominated sort, time complexity},
  location	= {Amsterdam, The Netherlands},
  series	= {GECCO '13}
}

@Article{	  gander2019solvers,
  author	= {Gander, Martin J. and Zhang, Hui},
  title		= {A Class of Iterative Solvers for the Helmholtz Equation:
		  Factorizations, Sweeping Preconditioners, Source Transfer,
		  Single Layer Potentials, Polarized Traces, and Optimized
		  Schwarz Methods},
  journal	= {SIAM Review},
  volume	= {61},
  number	= {1},
  pages		= {3-76},
  year		= {2019},
  doi		= {10.1137/16M109781X},
  url		= { https://doi.org/10.1137/16M109781X }
}

@InProceedings{	  garcia2006initialization,
  author	= "Garc{\'i}a-Arnau, M. and Manrique, D. and R{\'i}os, J. and
		  Rodr{\'i}guez-Pat{\'o}n, A.",
  editor	= "Bramer, Max and Coenen, Frans and Tuson, Andrew",
  title		= "Initialization Method for Grammar-Guided Genetic
		  Programming",
  booktitle	= "Research and Development in Intelligent Systems XXIII",
  year		= "2007",
  publisher	= "Springer London",
  address	= "London",
  pages		= "32--44",
  abstract	= "This paper proposes a new tree-generation algorithm for
		  grammarguided genetic programming that includes a parameter
		  to control the maximum size of the trees to be generated.
		  An important feature of this algorithm is that the initial
		  populations generated are adequately distributed in terms
		  of tree size and distribution within the search space.
		  Consequently, genetic programming systems starting from the
		  initial populations generated by the proposed method have a
		  higher convergence speed. Two different problems have been
		  chosen to carry out the experiments: a laboratory test
		  involving searching for arithmetical equalities and the
		  real-world task of breast cancer prognosis. In both
		  problems, comparisons have been made to another five
		  important initialization methods.",
  isbn		= "978-1-84628-663-6",
  doi		= "10.1007/978-1-84628-663-6_3"
}

@Article{	  gijzen2007analysis,
  author	= {van Gijzen, M. B. and Erlangga, Y. A. and Vuik, C.},
  title		= {Spectral Analysis of the Discrete Helmholtz Operator
		  Preconditioned with a Shifted Laplacian},
  journal	= {SIAM Journal on Scientific Computing},
  volume	= {29},
  number	= {5},
  pages		= {1942-1958},
  year		= {2007},
  doi		= {10.1137/060661491},
  url		= { https://doi.org/10.1137/060661491 }
}

@InCollection{	  goldberg1991comparative,
  title		= {A comparative analysis of selection schemes used in
		  genetic algorithms},
  author	= {Goldberg, David E and Deb, Kalyanmoy},
  booktitle	= {Foundations of genetic algorithms},
  volume	= {1},
  pages		= {69--93},
  year		= {1991},
  publisher	= {Elsevier}
}

@Article{	  gong2015distributed,
  title		= "Distributed evolutionary algorithms and their models: A
		  survey of the state-of-the-art",
  journal	= "Applied Soft Computing",
  volume	= "34",
  pages		= "286 - 300",
  year		= "2015",
  issn		= "1568-4946",
  doi		= "https://doi.org/10.1016/j.asoc.2015.04.061",
  url		= "http://www.sciencedirect.com/science/article/pii/S1568494615002987",
  author	= "Yue-Jiao Gong and Wei-Neng Chen and Zhi-Hui Zhan and Jun
		  Zhang and Yun Li and Qingfu Zhang and Jing-Jing Li",
  keywords	= "Distributed evolutionary computation, Coevolutionary
		  computation, Evolutionary algorithms, Global optimization,
		  Multiobjective optimization",
  abstract	= "The increasing complexity of real-world optimization
		  problems raises new challenges to evolutionary computation.
		  Responding to these challenges, distributed evolutionary
		  computation has received considerable attention over the
		  past decade. This article provides a comprehensive survey
		  of the state-of-the-art distributed evolutionary algorithms
		  and models, which have been classified into two groups
		  according to their task division mechanism.
		  Population-distributed models are presented with
		  master-slave, island, cellular, hierarchical, and pool
		  architectures, which parallelize an evolution task at
		  population, individual, or operation levels.
		  Dimension-distributed models include coevolution and
		  multi-agent models, which focus on dimension reduction.
		  Insights into the models, such as synchronization,
		  homogeneity, communication, topology, speedup, advantages
		  and disadvantages are also presented and discussed. The
		  study of these models helps guide future development of
		  different and/or improved algorithms. Also highlighted are
		  recent hotspots in this area, including the cloud and
		  MapReduce-based implementations, GPU and CUDA-based
		  implementations, distributed evolutionary multiobjective
		  optimization, and real-world applications. Further, a
		  number of future research directions have been discussed,
		  with a conclusion that the development of distributed
		  evolutionary computation will continue to flourish."
}

@Article{	  gray1995migration,
  title		= {Migration from topography: Improving the near-surface
		  image},
  author	= {Gray, Samuel H. and Marfurt, Kurt J.},
  journal	= {Canadian Journal of Exploration Geophysics},
  volume	= {31},
  number	= {1-2},
  pages		= {18-24},
  year		= {1995}
}

@InProceedings{	  greenfeld2019learning,
  title		= {Learning to Optimize Multigrid {PDE} Solvers},
  author	= {Greenfeld, Daniel and Galun, Meirav and Basri, Ronen and
		  Yavneh, Irad and Kimmel, Ron},
  booktitle	= {Proceedings of the 36th International Conference on
		  Machine Learning},
  pages		= {2415--2423},
  year		= {2019},
  editor	= {Chaudhuri, Kamalika and Salakhutdinov, Ruslan},
  volume	= {97},
  series	= {Proceedings of Machine Learning Research},
  month		= {09--15 Jun},
  publisher	= {PMLR},
  pdf		= {http://proceedings.mlr.press/v97/greenfeld19a/greenfeld19a.pdf},
  url		= {https://proceedings.mlr.press/v97/greenfeld19a.html},
  abstract	= {Constructing fast numerical solvers for partial
		  differential equations (PDEs) is crucial for many
		  scientific disciplines. A leading technique for solving
		  large-scale PDEs is using multigrid methods. At the core of
		  a multigrid solver is the prolongation matrix, which
		  relates between different scales of the problem. This
		  matrix is strongly problem-dependent, and its optimal
		  construction is critical to the efficiency of the solver.
		  In practice, however, devising multigrid algorithms for new
		  problems often poses formidable challenges. In this paper
		  we propose a framework for learning multigrid solvers. Our
		  method learns a (single) mapping from discretized PDEs to
		  prolongation operators for a broad class of 2D diffusion
		  problems. We train a neural network once for the entire
		  class of PDEs, using an efficient and unsupervised loss
		  function. Our tests demonstrate improved convergence rates
		  compared to the widely used Black-Box multigrid scheme,
		  suggesting that our method successfully learned rules for
		  constructing prolongation matrices.}
}

@inproceedings{guibas2021efficient,
	title={Efficient Token Mixing for Transformers via Adaptive Fourier Neural Operators},
	author={Guibas, John and Mardani, Morteza and Li, Zongyi and Tao, Andrew and Anandkumar, Anima and Catanzaro, Bryan},
	booktitle={International Conference on Learning Representations},
	year={2021}
}

@Book{		  hackbusch2013multi,
  title		= {Multi-Grid Methods and Applications},
  author	= {Hackbusch, Wolfgang},
  year		= {1985},
  publisher	= {Springer-Verlag}
}

@Book{		  hager2010introduction,
  title		= {Introduction to high performance computing for scientists
		  and engineers},
  author	= {Hager, Georg and Wellein, Gerhard},
  year		= {2010},
  publisher	= {CRC Press}
}

@article{hager2016exploring,
	title={Exploring performance and power properties of modern multi-core chips via simple machine models},
	author={Hager, Georg and Treibig, Jan and Habich, Johannes and Wellein, Gerhard},
	journal={Concurrency and computation: practice and experience},
	volume={28},
	number={2},
	pages={189--210},
	year={2016},
	url		= {https://doi.org/10.1002/cpe.3180},
	doi		= {10.1002/cpe.3180},
	publisher={Wiley Online Library}
}

@Article{	  hansen2001completely,
  author	= {Hansen, Nikolaus and Ostermeier, Andreas},
  title		= {Completely Derandomized Self-Adaptation in Evolution
		  Strategies},
  year		= {2001},
  issue_date	= {June 2001},
  publisher	= {MIT Press},
  address	= {Cambridge, MA, USA},
  volume	= {9},
  number	= {2},
  issn		= {1063-6560},
  url		= {https://doi.org/10.1162/106365601750190398},
  doi		= {10.1162/106365601750190398},
  journal	= {Evol. Comput.},
  month		= jun,
  pages		= {159–195},
  numpages	= {37}
}

@Article{	  helmuth2014solving,
  title		= {Solving uncompromising problems with lexicase selection},
  author	= {Helmuth, Thomas and Spector, Lee and Matheson, James},
  journal	= {IEEE Transactions on Evolutionary Computation},
  volume	= {19},
  number	= {5},
  pages		= {630--643},
  year		= {2014},
  publisher	= {IEEE}
}

@inproceedings{hennigh2021nvidia,
	title={NVIDIA SimNet™: An AI-accelerated multi-physics simulation framework},
	author={Hennigh, Oliver and Narasimhan, Susheela and Nabian, Mohammad Amin and Subramaniam, Akshay and Tangsali, Kaustubh and Fang, Zhiwei and Rietmann, Max and Byeon, Wonmin and Choudhry, Sanjay},
	booktitle={International Conference on Computational Science},
	pages={447--461},
	year={2021},
	organization={Springer}
}

@InProceedings{	  henson2003multigrid,
  author	= {Van Emden Henson},
  title		= {{Multigrid methods nonlinear problems: an overview}},
  volume	= {5016},
  booktitle	= {Computational Imaging},
  editor	= {Charles A. Bouman and Robert L. Stevenson},
  organization	= {International Society for Optics and Photonics},
  publisher	= {SPIE},
  pages		= {36 -- 48},
  keywords	= {Multigrid, FAS, nonlinear, Newton's method},
  year		= {2003},
  doi		= {10.1117/12.499473},
  url		= {https://doi.org/10.1117/12.499473}
}


@MastersThesis{hoefer2020comparing,
	author     =     {Daniel Höfer},
	title     =     {Comparing {MCTS} with {G}enetic {A}lgorithms for
	{O}ptimizing {M}ultigrid {M}ethods},
	school     =     {Friedrich-Alexander-Universität Erlangen-Nürnberg},
	address     =     {Germany},
	url	= {https://www10.cs.fau.de/publications/theses/2020/Hoefer_MT_2020.pdf},
	year     =     {2020}
}

@Book{		  holzapfel2001nonlinear,
  title		= {Nonlinear Solid Mechanics: A Continuum Approach for
		  Engineering},
  author	= {Holzapfel, Gerhard},
  year		= {2001},
  publisher	= {John Wiley and Sons}
}

@article{hornik1989multilayer,
	title={Multilayer feedforward networks are universal approximators},
	author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	journal={Neural networks},
	volume={2},
	number={5},
	pages={359--366},
	year={1989},
	publisher={Elsevier}
}


@Article{	  hsieh2019learning,
  title		= {Learning neural PDE solvers with convergence guarantees},
  author	= {Hsieh, Jun-Ting and Zhao, Shengjia and Eismann, Stephan
		  and Mirabella, Lucia and Ermon, Stefano},
  journal	= {arXiv preprint},
  year		= {2019},
  eprint	= {1906.01200}
}

@Article{	  huang2021learning,
  doi		= {10.48550/ARXIV.2102.12071},
  url		= {https://arxiv.org/abs/2102.12071},
  author	= {Huang, Ru and Li, Ruipeng and Xi, Yuanzhe},
  keywords	= {Numerical Analysis (math.NA), Machine Learning (cs.LG),
		  FOS: Mathematics, FOS: Mathematics, FOS: Computer and
		  information sciences, FOS: Computer and information
		  sciences},
  title		= {Learning optimal multigrid smoothers via neural networks},
  publisher	= {arXiv},
  year		= {2021},
  copyright	= {arXiv.org perpetual, non-exclusive license}
}

@Article{	  kahl2020automated,
  title		= {Automated local Fourier analysis (aLFA)},
  author	= {Kahl, Karsten and Kintscher, Nils},
  journal	= {BIT Numerical Mathematics},
  volume	= {60},
  number	= {3},
  pages		= {651--686},
  year		= {2020},
  publisher	= {Springer}
}

@Article{	  karniadakis2021physics,
  author	= {Karniadakis, George Em and Kevrekidis, Ioannis G. and Lu,
		  Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
  title		= {Physics-informed machine learning},
  journal	= {Nature Reviews Physics},
  year		= {2021},
  month		= {Jun},
  day		= {01},
  volume	= {3},
  number	= {6},
  pages		= {422-440},
  abstract	= {Despite great progress in simulating multiphysics problems
		  using the numerical discretization of partial differential
		  equations (PDEs), one still cannot seamlessly incorporate
		  noisy data into existing algorithms, mesh generation
		  remains complex, and high-dimensional problems governed by
		  parameterized PDEs cannot be tackled. Moreover, solving
		  inverse problems with hidden physics is often prohibitively
		  expensive and requires different formulations and elaborate
		  computer codes. Machine learning has emerged as a promising
		  alternative, but training deep neural networks requires big
		  data, not always available for scientific problems.
		  Instead, such networks can be trained from additional
		  information obtained by enforcing the physical laws (for
		  example, at random points in the continuous space-time
		  domain). Such physics-informed learning integrates (noisy)
		  data and mathematical models, and implements them through
		  neural networks or other kernel-based regression networks.
		  Moreover, it may be possible to design specialized network
		  architectures that automatically satisfy some of the
		  physical invariants for better accuracy, faster training
		  and improved generalization. Here, we review some of the
		  prevailing trends in embedding physics into machine
		  learning, present some of the current capabilities and
		  limitations and discuss diverse applications of
		  physics-informed learning both for forward and inverse
		  problems, including discovering hidden physics and tackling
		  high-dimensional problems.},
  issn		= {2522-5820},
  doi		= {10.1038/s42254-021-00314-5},
  url		= {https://doi.org/10.1038/s42254-021-00314-5}
}

@Article{	  katrutsa2020black,
  title		= {Black-box learning of multigrid parameters},
  journal	= {Journal of Computational and Applied Mathematics},
  volume	= {368},
  pages		= {112524},
  year		= {2020},
  issn		= {0377-0427},
  doi		= {https://doi.org/10.1016/j.cam.2019.112524},
  url		= {https://www.sciencedirect.com/science/article/pii/S0377042719305291},
  author	= {Alexandr Katrutsa and Talgat Daulbaev and Ivan Oseledets},
  keywords	= {Geometric multigrid method, Automatic differentiation,
		  Spectral radius minimization, Helmholtz equation, Poisson
		  equation},
  abstract	= {This paper studies the optimality of the restriction and
		  prolongation operators in the geometric multigrid method
		  (GMG). GMG is used in solving discretized partial
		  differential equation (PDE) and it relies greatly on the
		  restriction and prolongation operators. Many methods to
		  find these operators were proposed, but most of them have
		  limited optimality proofs. To study their optimality we
		  introduce stochastic convergence functional, which
		  estimates the spectral radius of the iteration matrix for
		  given GMG parameters. We implement the GMG method in a
		  modern machine learning framework that can automatically
		  compute the gradients of the introduced convergence
		  functional with respect to restriction and prolongation
		  operators. Therefore, we can minimize the proposed
		  functional starting from some initial parameters and get
		  better ones after some iterations of stochastic gradient
		  descent. To illustrate the performance of the proposed
		  approach, we carry out experiments on the discretized
		  Poisson equation, Helmholtz equation and singularly
		  perturbed convection–diffusion equation and demonstrate
		  that proposed approach gives operators, which lead to
		  faster convergence.}
}

@article{kharazmi2019variational,
doi = {10.48550/ARXIV.1912.00873},
url = {https://arxiv.org/abs/1912.00873},
author = {Kharazmi, E. and Zhang, Z. and Karniadakis, G. E.},
keywords = {Neural and Evolutionary Computing (cs.NE), Machine Learning (cs.LG), Numerical Analysis (math.NA), Computational Physics (physics.comp-ph), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Mathematics, FOS: Mathematics, FOS: Physical sciences, FOS: Physical sciences},
title = {Variational Physics-Informed Neural Networks For Solving Partial Differential Equations},
publisher = {arXiv},
year = {2019},
copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{kharazmi2021hp,
	title={hp-VPINNs: Variational physics-informed neural networks with domain decomposition},
	author={Kharazmi, Ehsan and Zhang, Zhongqiang and Karniadakis, George Em},
	journal={Computer Methods in Applied Mechanics and Engineering},
	volume={374},
	pages={113547},
	year={2021},
	publisher={Elsevier}
}

@book{knupp2020fundamentals,
	title={Fundamentals of grid generation},
	author={Knupp, Patrick and Steinberg, Stanly},
	year={2020},
	publisher={CRC press}
}


@InProceedings{	  koestler2004extrapolation,
  author	= "Köstler, H. and Rüde, U.",
  editor	= "Bubak, Marian and van Albada, Geert Dick and Sloot, Peter
		  M. A. and Dongarra, Jack",
  title		= "Extrapolation Techniques for Computing Accurate Solutions
		  of Elliptic Problems with Singular Solutions",
  booktitle	= "Computational Science - ICCS 2004",
  year		= "2004",
  publisher	= "Springer Berlin Heidelberg",
  address	= "Berlin, Heidelberg",
  pages		= "410--417",
  abstract	= "Generalized functions occur in many practical applications
		  as source terms in partial differential equations. Typical
		  examples are point loads and dipoles as source terms for
		  electrostatic potentials. For analyzing the accuracy of
		  such computations, standard techniques cannot be used,
		  since they rely on global smoothness. At the singularity,
		  the solution tends to infinity and therefore standard error
		  norms will not even converge.",
  isbn		= "978-3-540-25944-2",
  url		= "https://doi.org/10.1007/978-3-540-25944-2_54"
}

@Article{	  kostler2020code,
  title		= {Code generation approaches for parallel geometric
		  multigrid solvers},
  author	= {K{\"o}stler, Harald and Heisig, Marco and Kohl, Nils and
		  Kuckuk, Sebastian and Bauer, Martin and R{\"u}de, Ulrich},
  journal	= {Analele Universitatii Ovidius Constanta - Seria
		  Matematica},
  volume	= {28},
  number	= {3},
  pages		= {123--152},
  year		= {2020}
}

@Article{	  kovachki2021neural,
  doi		= {10.48550/ARXIV.2108.08481},
  url		= {https://arxiv.org/abs/2108.08481},
  author	= {Kovachki, Nikola and Li, Zongyi and Liu, Burigede and
		  Azizzadenesheli, Kamyar and Bhattacharya, Kaushik and
		  Stuart, Andrew and Anandkumar, Anima},
  keywords	= {Machine Learning (cs.LG), Numerical Analysis (math.NA),
		  FOS: Computer and information sciences, FOS: Computer and
		  information sciences, FOS: Mathematics, FOS: Mathematics},
  title		= {Neural Operator: Learning Maps Between Function Spaces},
  publisher	= {arXiv},
  year		= {2021},
  copyright	= {arXiv.org perpetual, non-exclusive license}
}

@Book{		  koza1994genetic,
  author	= {Koza, John R.},
  title		= {Genetic programming as a means for programming computers
		  by natural selection},
  journal	= {Statistics and Computing},
  year		= {1994},
  month		= {Jun},
  day		= {01},
  volume	= {4},
  number	= {2},
  pages		= {87-112},
  abstract	= {Many seemingly different problems in machine learning,
		  artificial intelligence, and symbolic processing can be
		  viewed as requiring the discovery of a computer program
		  that produces some desired output for particular inputs.
		  When viewed in this way, the process of solving these
		  problems becomes equivalent to searching a space of
		  possible computer programs for a highly fit individual
		  computer program. The recently developed genetic
		  programming paradigm described herein provides a way to
		  search the space of possible computer programs for a highly
		  fit individual computer program to solve (or approximately
		  solve) a surprising variety of different problems from
		  different fields. In genetic programming, populations of
		  computer programs are genetically bred using the Darwinian
		  principle of survival of the fittest and using a genetic
		  crossover (sexual recombination) operator appropriate for
		  genetically mating computer programs. Genetic programming
		  is illustrated via an example of machine learning of the
		  Boolean 11-multiplexer function and symbolic regression of
		  the econometric exchange equation from noisy empirical
		  data.},
  issn		= {1573-1375},
  doi		= {10.1007/BF00175355},
  url		= {https://doi.org/10.1007/BF00175355}
}

@Article{	  koza2010human,
  title		= {Human-competitive results produced by genetic
		  programming},
  author	= {Koza, John R.},
  journal	= {Genetic Programming and Evolvable Machines},
  volume	= {11},
  number	= {3-4},
  pages		= {251--284},
  year		= {2010},
  publisher	= {Springer-Verlag},
  doi		= {10.1007/s10710-010-9112-3},
  url		= {https://doi.org/10.1007/s10710-010-9112-3}
}

@Article{	  kuckuk2016automatic,
  author	= {Kuckuk, Sebastian and Köstler, Harald},
  title		= {Automatic Generation of Massively Parallel Codes from
		  ExaSlang},
  journal	= {Computation},
  volume	= {4},
  year		= {2016},
  number	= {3},
  article-number= {27},
  url		= {https://www.mdpi.com/2079-3197/4/3/27},
  issn		= {2079-3197},
  abstract	= {Domain-specific languages (DSLs) have the potential to
		  provide an intuitive interface for specifying problems and
		  solutions for domain experts. Based on this, code
		  generation frameworks can produce compilable source code.
		  However, apart from optimizing execution performance,
		  parallelization is key for pushing the limits in problem
		  size and an essential ingredient for exascale performance.
		  We discuss necessary concepts for the introduction of such
		  capabilities in code generators. In particular, those for
		  partitioning the problem to be solved and accessing the
		  partitioned data are elaborated. Furthermore, possible
		  approaches to expose parallelism to users through a given
		  DSL are discussed. Moreover, we present the implementation
		  of these concepts in the ExaStencils framework. In its
		  scope, a code generation framework for highly optimized and
		  massively parallel geometric multigrid solvers is
		  developed. It uses specifications from its multi-layered
		  external DSL ExaSlang as input. Based on a general version
		  for generating parallel code, we develop and implement
		  widely applicable extensions and optimizations. Finally, a
		  performance study of generated applications is conducted on
		  the JuQueen supercomputer.},
  doi		= {10.3390/computation4030027}
}

@InProceedings{	  la2016epsilon,
  title		= {Epsilon-lexicase selection for regression},
  author	= {La Cava, William and Spector, Lee and Danai, Kourosh},
  booktitle	= {Proceedings of the Genetic and Evolutionary Computation
		  Conference 2016},
  pages		= {741--748},
  year		= {2016}
}

@article{lagaris1998artificial,
	title={Artificial neural networks for solving ordinary and partial differential equations},
	author={Lagaris, Isaac E and Likas, Aristidis and Fotiadis, Dimitrios I},
	journal={IEEE transactions on neural networks},
	volume={9},
	number={5},
	pages={987--1000},
	year={1998},
	publisher={IEEE}
}


@InProceedings{	  lengauer2014exastencils,
  title		= {ExaStencils: Advanced stencil-code engineering},
  author	= {Lengauer, Christian and Apel, Sven and Bolten, Matthias
		  and Gr{\"o}{\ss}linger, Armin and Hannig, Frank and
		  K{\"o}stler, Harald and R{\"u}de, Ulrich and Teich,
		  J{\"u}rgen and Grebhahn, Alexander and Kronawitter, Stefan
		  and others},
  booktitle	= {European Conference on Parallel Processing},
  pages		= {553--564},
  year		= {2014},
  organization	= {Springer}
}

@InProceedings{	  lengauer2020exastencils,
	author="Lengauer, Christian
	and Apel, Sven
	and Bolten, Matthias
	and Chiba, Shigeru
	and R{\"u}de, Ulrich
	and Teich, J{\"u}rgen
	and Gr{\"o}{\ss}linger, Armin
	and Hannig, Frank
	and K{\"o}stler, Harald
	and Claus, Lisa
	and Grebhahn, Alexander
	and Groth, Stefan
	and Kronawitter, Stefan
	and Kuckuk, Sebastian
	and Rittich, Hannah
	and Schmitt, Christian
	and Schmitt, Jonas",
	editor	= "Bungartz, Hans-Joachim and Reiz, Severin and Uekermann,
	Benjamin and Neumann, Philipp and Nagel, Wolfgang E.",
	title		= "ExaStencils: Advanced Multigrid Solver Generation",
	booktitle	= "Software for Exascale Computing - SPPEXA 2016-2019",
	year		= "2020",
	publisher	= "Springer International Publishing",
	address	= "Cham",
	pages		= "405--452",
	abstract	= "Present-day stencil codes are implemented in
	general-purpose programming languages, such as Fortran, C,
	or Java, Python or derivates thereof, and harnesses for
	parallelism, such as OpenMP, OpenCL or MPI. Project
	ExaStencils pursued a domain-specific approach with a
	language, called ExaSlang, that is stratified into four
	layers of abstraction, the most abstract being the
	formulation in continuous mathematics and the most concrete
	a full, automatically generated implementation. At every
	layer, the corresponding language expresses not only
	computational directives but also domain knowledge of the
	problem and platform to be leveraged for optimization. We
	describe the approach, the software technology behind it
	and several case studies that demonstrate its feasibility
	and versatility: high-performance stencil codes can be
	engineered, ported and optimized more easily and
	effectively.",
	isbn		= "978-3-030-47956-5",
	url		= "https://doi.org/10.1007/978-3-030-47956-5_14"
}

@Article{	  li2020fourier,
  doi		= {10.48550/ARXIV.2010.08895},
  url		= {https://arxiv.org/abs/2010.08895},
  author	= {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli,
		  Kamyar and Liu, Burigede and Bhattacharya, Kaushik and
		  Stuart, Andrew and Anandkumar, Anima},
  keywords	= {Machine Learning (cs.LG), Numerical Analysis (math.NA),
		  FOS: Computer and information sciences, FOS: Computer and
		  information sciences, FOS: Mathematics, FOS: Mathematics},
  title		= {Fourier Neural Operator for Parametric Partial
		  Differential Equations},
  publisher	= {arXiv},
  year		= {2020},
  copyright	= {arXiv.org perpetual, non-exclusive license}
}

@Article{	  li2021physics,
  doi		= {10.48550/ARXIV.2111.03794},
  url		= {https://arxiv.org/abs/2111.03794},
  author	= {Li, Zongyi and Zheng, Hongkai and Kovachki, Nikola and
		  Jin, David and Chen, Haoxuan and Liu, Burigede and
		  Azizzadenesheli, Kamyar and Anandkumar, Anima},
  keywords	= {Machine Learning (cs.LG), Numerical Analysis (math.NA),
		  FOS: Computer and information sciences, FOS: Computer and
		  information sciences, FOS: Mathematics, FOS: Mathematics},
  title		= {Physics-Informed Neural Operator for Learning Partial
		  Differential Equations},
  publisher	= {arXiv},
  year		= {2021},
  copyright	= {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{liu2022evolvability,
	author = {Liu, Dazhuang and Virgolin, Marco and Alderliesten, Tanja and Bosman, Peter A. N.},
	title = {Evolvability Degeneration in Multi-Objective Genetic Programming for Symbolic Regression},
	year = {2022},
	isbn = {9781450392372},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3512290.3528787},
	doi = {10.1145/3512290.3528787},
	abstract = {Genetic programming (GP) is one of the best approaches today to discover symbolic regression models. To find models that trade off accuracy and complexity, the non-dominated sorting genetic algorithm II (NSGA-II) is widely used. Unfortunately, it has been shown that NSGA-II can be inefficient: in early generations, low-complexity models over-replicate and take over most of the population. Consequently, studies have proposed different approaches to promote diversity. Here, we study the root of this problem, in order to design a superior approach. We find that the over-replication of low complexity-models is due to a lack of evolvability, i.e., the inability to produce offspring with improved accuracy. We therefore extend NSGA-II to track, over time, the evolvability of models of different levels of complexity. With this information, we limit how many models of each complexity level are allowed to survive the generation. We compare this new version of NSGA-II, evoNSGA-II, with the use of seven existing multi-objective GP approaches on ten widely-used data sets, and find that evoNSGA-II is equal or superior to using these approaches in almost all comparisons. Furthermore, our results confirm that evoNSGA-II behaves as intended: models that are more evolvable form the majority of the population. Code: https://github.com/dzhliu/evoNSGA-II},
	booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
	pages = {973–981},
	numpages = {9},
	keywords = {genetic programming, multi-objective optimization, evolvability, symbolic regression},
	location = {Boston, Massachusetts},
	series = {GECCO '22}
}

@Book{		  linz2006introduction,
  title		= {An Introduction to Formal Languages and Automata},
  author	= {Linz, Peter and Rodger, Susan H.},
  year		= {2022},
  publisher	= {Jones \& Bartlett Learning}
}

@Article{	  lipowski2012roulette,
  title		= {Roulette-wheel selection via stochastic acceptance},
  author	= {Lipowski, Adam and Lipowska, Dorota},
  journal	= {Physica A: Statistical Mechanics and its Applications},
  volume	= {391},
  number	= {6},
  pages		= {2193--2196},
  year		= {2012},
  publisher	= {Elsevier}
}

@article{lu2021learning,
	title={Learning nonlinear operators via DeepONet based on the universal approximation theorem of operators},
	author={Lu, Lu and Jin, Pengzhan and Pang, Guofei and Zhang, Zhongqiang and Karniadakis, George Em},
	journal={Nature Machine Intelligence},
	volume={3},
	number={3},
	pages={218--229},
	year={2021},
	publisher={Nature Publishing Group}
}

@article{lu2021deepxde,
	author  = {Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis, George Em},
	title   = {{DeepXDE}: A deep learning library for solving differential equations},
	journal = {SIAM Review},
	volume  = {63},
	number  = {1},
	pages   = {208-228},
	year    = {2021},
	doi     = {10.1137/19M1274067}
}

@InProceedings{	  luz2020learning,
  title		= {Learning Algebraic Multigrid Using Graph Neural Networks},
  author	= {Luz, Ilay and Galun, Meirav and Maron, Haggai and Basri,
		  Ronen and Yavneh, Irad},
  booktitle	= {Proceedings of the 37th International Conference on
		  Machine Learning},
  pages		= {6489--6499},
  year		= {2020},
  editor	= {III, Hal Daumé and Singh, Aarti},
  volume	= {119},
  series	= {Proceedings of Machine Learning Research},
  month		= {13--18 Jul},
  publisher	= {PMLR},
  pdf		= {http://proceedings.mlr.press/v119/luz20a/luz20a.pdf},
  url		= {https://proceedings.mlr.press/v119/luz20a.html},
  abstract	= {Efficient numerical solvers for sparse linear systems are
		  crucial in science and engineering. One of the fastest
		  methods for solving large-scale sparse linear systems is
		  algebraic multigrid (AMG). The main challenge in the
		  construction of AMG algorithms is the selection of the
		  prolongation operator—a problem-dependent sparse matrix
		  which governs the multiscale hierarchy of the solver and is
		  critical to its efficiency. Over many years, numerous
		  methods have been developed for this task, and yet there is
		  no known single right answer except in very special cases.
		  Here we propose a framework for learning AMG prolongation
		  operators for linear systems with sparse symmetric positive
		  (semi-) definite matrices. We train a single graph neural
		  network to learn a mapping from an entire class of such
		  matrices to prolongation operators, using an efficient
		  unsupervised loss function. Experiments on a broad class of
		  problems demonstrate improved convergence rates compared to
		  classical AMG, demonstrating the potential utility of
		  neural networks for developing sparse system solvers.}
}

@article{markidis2021old,
	title={The old and the new: Can physics-informed deep-learning replace traditional linear solvers?},
	author={Markidis, Stefano},
	journal={Frontiers in big Data},
	pages={92},
	publisher={Frontiers}
}


@Article{	  martin2006marmousi2,
  author	= {Gary S. Martin and Robert Wiley and Kurt J. Marfurt},
  title		= {Marmousi2: An elastic upgrade for Marmousi},
  journal	= {The Leading Edge},
  volume	= {25},
  number	= {2},
  pages		= {156-166},
  year		= {2006},
  doi		= {10.1190/1.2172306},
  url		= { https://doi.org/10.1190/1.2172306
		  
		  },
  abstract	= { The original Marmousi model was created by a consortium
		  led by the Institut Français du Pétrole (IFP) in 1988.
		  Since its creation, the model and its acoustic
		  finite-difference synthetic data have been used by hundreds
		  of researchers throughout the world for a multitude of
		  geophysical purposes, and to this day remains one of the
		  most published geophysical data sets. The advancement in
		  computer hardware capabilities since the late 1980s has
		  made it possible to perform a major upgrade to the model
		  and data set, thereby extending the usefulness of the model
		  for, hopefully, some time to come. This paper outlines the
		  creation of an updated and upgraded Marmousi model and data
		  set which we have named Marmousi2. }
}

@Article{	  mckay2010grammar,
  author	= {McKay, Robert I. and Hoai, Nguyen Xuan and Whigham, Peter
		  Alexander and Shan, Yin and O'Neill, Michael},
  title		= {Grammar-based Genetic Programming: a survey},
  journal	= {Genetic Programming and Evolvable Machines},
  year		= {2010},
  month		= {Sep},
  day		= {01},
  volume	= {11},
  number	= {3},
  pages		= {365-396},
  abstract	= {Grammar formalisms are one of the key representation
		  structures in Computer Science. So it is not surprising
		  that they have also become important as a method for
		  formalizing constraints in Genetic Programming (GP).
		  Practical grammar-based GP systems first appeared in the
		  mid 1990s, and have subsequently become an important strand
		  in GP research and applications. We trace their subsequent
		  rise, surveying the various grammar-based formalisms that
		  have been used in GP and discussing the contributions they
		  have made to the progress of GP. We illustrate these
		  contributions with a range of applications of grammar-based
		  GP, showing how grammar formalisms contributed to the
		  solutions of these problems. We briefly discuss the likely
		  future development of grammar-based GP systems, and
		  conclude with a brief summary of the field.},
  issn		= {1573-7632},
  doi		= {10.1007/s10710-010-9109-y},
  url		= {https://doi.org/10.1007/s10710-010-9109-y}
}

@InProceedings{	  miller2008cartesian,
  title		= {Cartesian genetic programming},
  author	= {Miller, Julian Francis and Harding, Simon L},
  booktitle	= {Proceedings of the 10th annual conference companion on
		  Genetic and evolutionary computation},
  pages		= {2701--2726},
  year		= {2008}
}

@Article{	  montana1995strongly,
  author	= {Montana, David J.},
  title		= "{Strongly Typed Genetic Programming}",
  journal	= {Evolutionary Computation},
  volume	= {3},
  number	= {2},
  pages		= {199-230},
  year		= {1995},
  month		= {06},
  abstract	= "{Genetic programming is a powerful method for
		  automatically generating computer programs via the process
		  of natural selection (Koza, 1992). However, in its standard
		  form, there is no way to restrict the programs it generates
		  to those where the functions operate on appropriate data
		  types. In the case when the programs manipulate multiple
		  data types and contain functions designed to operate on
		  particular data types, this can lead to unnecessarily large
		  search times and/or unnecessarily poor generalization
		  performance. Strongly typed genetic programming (STGP) is
		  an enhanced version of genetic programming that enforces
		  data-type constraints and whose use of generic functions
		  and generic data types makes it more powerful than other
		  approaches to type-constraint enforcement. After describing
		  its operation, we illustrate its use on problems in two
		  domains, matrix/vector manipulation and list manipulation,
		  which require its generality. The examples are (1) the
		  multidimensional least-squares regression problem, (2) the
		  multidimensional Kalman filter, (3) the list manipulation
		  function NTH, and (4) the list manipulation function
		  MAPCAR.}",
  issn		= {1063-6560},
  doi		= {10.1162/evco.1995.3.2.199},
  url		= {https://doi.org/10.1162/evco.1995.3.2.199},
  eprint	= {https://direct.mit.edu/evco/article-pdf/3/2/199/1492842/evco.1995.3.2.199.pdf}
}

@Article{	  o2001grammatical,
  title		= {Grammatical evolution},
  author	= {O'Neill, Michael and Ryan, Conor},
  journal	= {IEEE Transactions on Evolutionary Computation},
  volume	= {5},
  number	= {4},
  pages		= {349--358},
  year		= {2001},
  publisher	= {IEEE}
}

@Article{	  oneill2001grammatical,
  author	= {O'Neill, M. and Ryan, C.},
  journal	= {IEEE Transactions on Evolutionary Computation},
  title		= {Grammatical evolution},
  year		= {2001},
  volume	= {5},
  number	= {4},
  pages		= {349-358},
  doi		= {10.1109/4235.942529}
}

@Article{	  oosterlee2003genetic,
  author	= {Oosterlee, C. W. and Wienands, R.},
  title		= {A Genetic Search for Optimal Multigrid Components Within a
		  Fourier Analysis Setting},
  journal	= {SIAM Journal on Scientific Computing},
  volume	= {24},
  number	= {3},
  pages		= {924-944},
  year		= {2003},
  doi		= {10.1137/S1064827501397950},
  url		= { https://doi.org/10.1137/S1064827501397950 }
}

@Article{	  oseikuffuor2010preconditioning,
  title		= "Preconditioning Helmholtz linear systems",
  journal	= "Applied Numerical Mathematics",
  volume	= "60",
  number	= "4",
  pages		= "420 - 431",
  year		= "2010",
  note		= "Special Issue: NUMAN 2008",
  issn		= "0168-9274",
  doi		= "https://doi.org/10.1016/j.apnum.2009.09.003",
  url		= "http://www.sciencedirect.com/science/article/pii/S0168927409001603",
  author	= "Daniel Osei-Kuffuor and Yousef Saad",
  keywords	= "Helmholtz equation, Preconditioning, Indefinite systems,
		  Diagonal perturbation, Complex diagonal shifts, Incomplete
		  LU factorization",
  abstract	= "Linear systems which originate from the simulation of wave
		  propagation phenomena can be very difficult to solve by
		  iterative methods. These systems are typically complex
		  valued and they tend to be highly indefinite, which renders
		  the standard ILU-based preconditioners ineffective. This
		  paper presents a study of ways to enhance standard
		  preconditioners by altering the diagonal by imaginary
		  shifts. Prior work indicates that modifying the diagonal
		  entries during the incomplete factorization process, by
		  adding to it purely imaginary values can improve the
		  quality of the preconditioner in a substantial way. Here we
		  propose simple algebraic heuristics to perform the shifting
		  and test these techniques with the ARMS and ILUT
		  preconditioners. Comparisons are made with applications
		  stemming from the diffraction of an acoustic wave incident
		  on a bounded obstacle (governed by the Helmholtz Wave
		  Equation)."
}

@article{pfaff2020learning,
	title={Learning mesh-based simulation with graph networks},
	author={Pfaff, Tobias and Fortunato, Meire and Sanchez-Gonzalez, Alvaro and Battaglia, Peter W},
	journal={arXiv preprint arXiv:2010.03409},
	year={2020}
}


@Book{		  pierce2002types,
  title		= {Types and programming languages},
  author	= {Pierce, Benjamin C and Benjamin, C},
  year		= {2002},
  publisher	= {MIT press}
}

@Book{		  pierce2019acoustics,
  title		= {Acoustics: An Introduction to Its Physical Principles and
		  Applications},
  author	= {Pierce, Allan D.},
  year		= {2019},
  publisher	= {Springer},
  url		= {10.1007/978-3-030-11214-1}
}

@Article{	  pitzer2012comprehensive,
  title		= {A comprehensive survey on fitness landscape analysis},
  author	= {Pitzer, Erik and Affenzeller, Michael},
  journal	= {Recent advances in intelligent engineering systems},
  pages		= {161--191},
  year		= {2012},
  publisher	= {Springer}
}

@Article{	  poli1998schema,
  title		= {Schema theory for genetic programming with one-point
		  crossover and point mutation},
  author	= {Poli, Riccardo and Langdon, William B},
  journal	= {Evolutionary Computation},
  volume	= {6},
  number	= {3},
  pages		= {231--252},
  year		= {1998},
  publisher	= {MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA
		  journals-info~…}
}

@Book{		  poli2008field,
  author	= {Poli, Riccardo and Langdon, William B. and McPhee,
		  Nicholas Freitag},
  title		= {A Field Guide to Genetic Programming},
  year		= {2008},
  isbn		= {1409200736},
  publisher	= {Lulu Enterprises, UK Ltd},
  abstract	= {Genetic programming (GP) is a systematic,
		  domain-independent method for getting computers to solve
		  problems automatically starting from a high-level statement
		  of what needs to be done. Using ideas from natural
		  evolution, GP starts from an ooze of random computer
		  programs, and progressively refines them through processes
		  of mutation and sexual recombination, until high-fitness
		  solutions emerge. All this without the user having to know
		  or specify the form or structure of solutions in advance.
		  GP has generated a plethora of human-competitive results
		  and applications, including novel scientific discoveries
		  and patentable inventions. This unique overview of this
		  exciting technique is written by three of the most active
		  scientists in GP. See www.gp-field-guide.org.uk for more
		  information on the book.}
}


@Article{	  rainville2012deap,
  author	= " F\'elix-Antoine Fortin and Fran\c{c}ois-Michel {De
		  Rainville} and Marc-Andr\'e Gardner and Marc Parizeau and
		  Christian Gagn\'e ",
  title		= { {DEAP}: Evolutionary Algorithms Made Easy },
  pages		= { 2171-2175 },
  volume	= { 13 },
  month		= { jul },
  year		= { 2012 },
  journal	= { Journal of Machine Learning Research }
}

@Article{	  raissi2019physics,
  title		= {Physics-informed neural networks: A deep learning
		  framework for solving forward and inverse problems
		  involving nonlinear partial differential equations},
  journal	= {Journal of Computational Physics},
  volume	= {378},
  pages		= {686-707},
  year		= {2019},
  issn		= {0021-9991},
  doi		= {https://doi.org/10.1016/j.jcp.2018.10.045},
  url		= {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
  author	= {M. Raissi and P. Perdikaris and G. E. Karniadakis},
  keywords	= {Data-driven scientific computing, Machine learning,
		  Predictive modeling, Runge–Kutta methods, Nonlinear
		  dynamics},
  abstract	= {We introduce physics-informed neural networks – neural
		  networks that are trained to solve supervised learning
		  tasks while respecting any given laws of physics described
		  by general nonlinear partial differential equations. In
		  this work, we present our developments in the context of
		  solving two main classes of problems: data-driven solution
		  and data-driven discovery of partial differential
		  equations. Depending on the nature and arrangement of the
		  available data, we devise two distinct types of algorithms,
		  namely continuous time and discrete time models. The first
		  type of models forms a new family of data-efficient
		  spatio-temporal function approximators, while the latter
		  type allows the use of arbitrarily accurate implicit
		  Runge–Kutta time stepping schemes with unlimited number
		  of stages. The effectiveness of the proposed framework is
		  demonstrated through a collection of classical problems in
		  fluids, quantum mechanics, reaction–diffusion systems,
		  and the propagation of nonlinear shallow-water waves.}
}

@PhDThesis{	  rittich2018extending,
  title		= {Extending and automating Fourier analysis for multigrid
		  methods},
  author	= {Rittich, Hannah},
  year		= {2018},
  school	= {Universit{\"a}t Wuppertal, Fakult{\"a}t f{\"u}r Mathematik
		  und Naturwissenschaften~…}
}

@article{rodrigo2017validity,
	title={On the validity of the local Fourier analysis},
	author={Rodrigo, Carmen and Gaspar, Francisco J and Zikatanov, Ludmil T},
	journal={arXiv preprint arXiv:1710.00408},
	year={2017}
}

@InCollection{	  ruge1987algebraic,
  title		= {Algebraic multigrid},
  author	= {Ruge, John W and St{\"u}ben, Klaus},
  booktitle	= {Multigrid methods},
  pages		= {73--130},
  year		= {1987},
  publisher	= {SIAM}
}

@Book{		  ryan2018handbook,
  title		= {Handbook of Grammatical Evolution},
  author	= {Ryan, Conor and O'Neill, Michael and Collins, J. J.},
  year		= {2018},
  publisher	= {Springer},
  doi		= {10.1007/978-3-319-78717-6}
}

@Book{		  saad2003iterative,
  author	= {Saad, Yousef},
  title		= {Iterative Methods for Sparse Linear Systems},
  publisher	= {Society for Industrial and Applied Mathematics},
  year		= {2003},
  doi		= {10.1137/1.9780898718003},
  address	= {},
  edition	= {Second},
  url		= {https://epubs.siam.org/doi/abs/10.1137/1.9780898718003}
}

@Book{		  salon1999numerical,
  title		= {Numerical methods in electromagnetism},
  author	= {Salon, Sheppard and Chari, M.},
  year		= {1999},
  publisher	= {Elsevier}
}

@InProceedings{	  schmitt2014exaslang,
  author	= {Schmitt, Christian and Kuckuk, Sebastian and Hannig, Frank
		  and Köstler, Harald and Teich, Jürgen},
  booktitle	= {2014 Fourth International Workshop on Domain-Specific
		  Languages and High-Level Frameworks for High Performance
		  Computing},
  title		= {ExaSlang: A Domain-Specific Language for Highly Scalable
		  Multigrid Solvers},
  year		= {2014},
  volume	= {},
  number	= {},
  pages		= {42-51},
  doi		= {10.1109/WOLFHPC.2014.11}
}

@InCollection{	  schmitt2016systems,
  title		= {Systems of partial differential equations in ExaSlang},
  author	= {Schmitt, Christian and Kuckuk, Sebastian and Hannig, Frank
		  and Teich, J{\"u}rgen and K{\"o}stler, Harald and R{\"u}de,
		  Ulrich and Lengauer, Christian},
  booktitle	= {Software for Exascale Computing-SPPEXA 2013-2015},
  pages		= {47--67},
  year		= {2016},
  publisher	= {Springer}
}

@article{schmitt2018automating,
	title={Automating the development of high-performance multigrid solvers},
	author={Schmitt, Christian and Kronawitter, Stefan and Hannig, Frank and Teich, J{\"u}rgen and Lengauer, Christian},
	journal={Proceedings of the IEEE},
	volume={106},
	number={11},
	pages={1969--1984},
	year={2018},
	publisher={IEEE}
}

@InProceedings{	  schmitt2020constructing,
  author	= {Schmitt, Jonas and Kuckuk, Sebastian and K\"{o}stler,
		  Harald},
  title		= {Constructing Efficient Multigrid Solvers with Genetic
		  Programming},
  year		= {2020},
  isbn		= {9781450371285},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  url		= {https://doi.org/10.1145/3377930.3389811},
  doi		= {10.1145/3377930.3389811},
  abstract	= {For many linear and nonlinear systems that arise from the
		  discretization of partial differential equations the
		  construction of an efficient multigrid solver is a
		  challenging task. Here we present a novel approach for the
		  optimization of geometric multigrid methods that is based
		  on evolutionary computation, a generic program optimization
		  technique inspired by the principle of natural evolution. A
		  multigrid solver is represented as a tree of mathematical
		  expressions which we generate based on a tailored grammar.
		  The quality of each solver is evaluated in terms of
		  convergence and compute performance using automated local
		  Fourier analysis (LFA) and roofline performance modeling,
		  respectively. Based on these objectives a multi-objective
		  optimization is performed using grammar-guided genetic
		  programming with a non-dominated sorting based selection.
		  To evaluate the model-based prediction and to target
		  concrete applications, scalable implementations of an
		  evolved solver can be automatically generated with the
		  ExaStencils framework. We demonstrate the effectiveness of
		  our approach by constructing multigrid solvers for a linear
		  elastic boundary value problem that are competitive with
		  common V- and W-cycles.},
  booktitle	= {Proceedings of the 2020 Genetic and Evolutionary
		  Computation Conference},
  pages		= {1012–1020},
  numpages	= {9},
  keywords	= {local fourier analysis, context-free grammar, geometric
		  multigrid, genetic programming, code generation},
  location	= {Canc\'{u}n, Mexico},
  series	= {GECCO '20}
}

@Article{	  schmitt2021evostencils,
  author	= {Schmitt, Jonas and Kuckuk, Sebastian and K{\"o}stler,
		  Harald},
  title		= {EvoStencils: a grammar-based genetic programming approach
		  for constructing efficient geometric multigrid methods},
  journal	= {Genetic Programming and Evolvable Machines},
  year		= {2021},
  month		= {Sep},
  day		= {03},
  issn		= {1573-7632},
  doi		= {10.1007/s10710-021-09412-w},
  url		= {https://doi.org/10.1007/s10710-021-09412-w}
}

@inproceedings{schmitt2022evolving,
	author = {Schmitt, Jonas and K\"{o}stler, Harald},
	title = {Evolving Generalizable Multigrid-Based Helmholtz Preconditioners with Grammar-Guided Genetic Programming},
	year = {2022},
	isbn = {9781450392372},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/3512290.3528688},
	doi = {10.1145/3512290.3528688},
	abstract = {Solving the indefinite Helmholtz equation is not only crucial for the understanding of many physical phenomena but also represents an outstandingly-difficult benchmark problem for the successful application of numerical methods. Here we introduce a new approach for evolving eficient preconditioned iterative solvers for Helmholtz problems with multi-objective grammar-guided genetic programming. Our approach is based on a novel context-free grammar, which enables the construction of multigrid preconditioners that employ a tailored sequence of operations on each discretization level. To find solvers that generalize well over the given domain, we propose a custom method of successive problem difficulty adaption, in which we evaluate a preconditioner's efficiency on increasingly ill-conditioned problem instances. We demonstrate our approach's effectiveness by evolving multigrid-based preconditioners for a two-dimensional indefinite Helmholtz problem that outperform several human-designed methods for different wavenumbers up to systems of linear equations with more than a million unknowns.},
	booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
	pages = {1009–1018},
	numpages = {10},
	keywords = {generalization, shifted laplacian, genetic programming, preconditioning, multigrid, grammar-based, helmholtz equation, multiobjective, partial differential equations, artificial intelligence},
	location = {Boston, Massachusetts},
	series = {GECCO '22}
}


@Article{	  sheikh2013deflation,
  author	= {Sheikh, A. H. and Lahaye, D. and Vuik, C.},
  title		= {On the convergence of shifted Laplace preconditioner
		  combined with multilevel deflation},
  journal	= {Numerical Linear Algebra with Applications},
  volume	= {20},
  number	= {4},
  pages		= {645-662},
  keywords	= {Helmholtz equation, shifted Laplace preconditioner,
		  multigrid deflation, Fourier analysis},
  doi		= {https://doi.org/10.1002/nla.1882},
  url		= {https://onlinelibrary.wiley.com/doi/abs/10.1002/nla.1882},
  abstract	= {SUMMARYDeflating the shifted Laplacian with geometric
		  multigrid vectors yields speedup. To verify this claim, we
		  investigate a simplified variant of Erlangga and Nabben
		  presented in [Erlangga and Nabben, ETNA,
		  2008;31:403–424]. We derive expressions for the
		  eigenvalues of the two-level preconditioner for the
		  one-dimensional problem. These expressions show that the
		  algorithm analyzed is not scalable. They also show that the
		  imaginary shift can be increased without delaying the
		  convergence of the outer Krylov acceleration. An increase
		  of the number of grid points per wavelength results in
		  convergence acceleration. This contrasts to the use of the
		  shifted Laplace preconditioner. Our analysis also shows
		  that the use of deflation results in a spectrum more
		  favorable to the convergence of the outer Krylov
		  acceleration. The near-null space components are still
		  insufficiently well resolved, and the number of iterations
		  increases with the wavenumber. In the two-dimensional case,
		  the number of near-zero eigenvalues is larger than in the
		  one-dimensional case. We perform numerical computations
		  with the two-level and multilevel versions of the algorithm
		  on constant and nonconstant wavenumber problems. Our
		  numerical results confirm our spectral analysis. Copyright
		  2013 John Wiley \& Sons, Ltd.},
  year		= {2013}
}

@article{sirignano2018dgm,
	title={DGM: A deep learning algorithm for solving partial differential equations},
	author={Sirignano, Justin and Spiliopoulos, Konstantinos},
	journal={Journal of computational physics},
	volume={375},
	pages={1339--1364},
	year={2018},
	publisher={Elsevier}
}


@Book{		  sterling2017high,
  title		= {High performance computing: modern systems and practices},
  author	= {Sterling, Thomas and Brodowicz, Maciej and Anderson,
		  Matthew},
  year		= {2017},
  publisher	= {Morgan Kaufmann}
}

@book{strikwerda2004finite,
	title={Finite difference schemes and partial differential equations},
	author={Strikwerda, John C},
	year={2004},
	publisher={SIAM}
}


@Article{	  stuben2001introduction,
  title		= {An introduction to algebraic multigrid},
  author	= {St{\"u}ben, Klaus},
  journal	= {Multigrid},
  pages		= {413--532},
  year		= {2001}
}

@InCollection{	  sudholt2015parallel,
  title		= {Parallel evolutionary algorithms},
  author	= {Sudholt, Dirk},
  booktitle	= {Springer Handbook of Computational Intelligence},
  pages		= {929--959},
  year		= {2015},
  publisher	= {Springer}
}

@Article{	  taghibakhshi2021optimization,
  author	= {Taghibakhshi, Ali and MacLachlan, Scott and Olson, Luke
		  and West, Matthew},
  booktitle	= {Advances in Neural Information Processing Systems},
  editor	= {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S.
		  Liang and J. Wortman Vaughan},
  pages		= {12129-12140},
  publisher	= {Curran Associates, Inc.},
  title		= {Optimization-Based Algebraic Multigrid Coarsening Using
		  Reinforcement Learning},
  url		= {https://proceedings.neurips.cc/paper/2021/file/6531b32f8d02fece98ff36a64a7c8260-Paper.pdf},
  volume	= {34},
  year		= {2021}
}

@Article{	  thekale2010optimizing,
  author	= {Thekale, A. and Gradl, T. and Klamroth, K. and Rüde, U.},
  title		= {Optimizing the number of multigrid cycles in the full
		  multigrid algorithm},
  journal	= {Numerical Linear Algebra with Applications},
  volume	= {17},
  number	= {2‐3},
  pages		= {199-210},
  keywords	= {full multigrid, optimization, Branch and Bound,
		  hierarchical hybrid grids},
  doi		= {10.1002/nla.697},
  url		= {https://onlinelibrary.wiley.com/doi/abs/10.1002/nla.697},
  abstract	= {Abstract Multigrid (MG) methods are among the most
		  efficient and widespread methods for solving large linear
		  systems of equations that arise, for example, from the
		  discretization of partial differential equations. In this
		  paper we introduce a new approach for optimizing the
		  computational cost of the full MG method to achieve a given
		  accuracy by determining the number of MG cycles on each
		  level. To achieve this, a very efficient and flexible
		  Branch and Bound algorithm is developed. The implementation
		  in the parallel finite element solver Hierarchical Hybrid
		  Grids leads to a significant reduction in CPU time.
		  Copyright © 2010 John Wiley \& Sons, Ltd.},
  year		= {2010}
}

@article{thuerey2020deep,
	title={Deep learning methods for Reynolds-averaged Navier--Stokes simulations of airfoil flows},
	author={Thuerey, Nils and Wei{\ss}enow, Konstantin and Prantl, Lukas and Hu, Xiangyu},
	journal={AIAA Journal},
	volume={58},
	number={1},
	pages={25--36},
	year={2020},
	publisher={American Institute of Aeronautics and Astronautics}
}


@Book{		  trottenberg2000multigrid,
  title		= {Multigrid},
  author	= {Trottenberg, Ulrich and Oosterlee, Cornelius W. and
		  Schuller, Anton},
  year		= {2000},
  publisher	= {Elsevier}
}

@Book{		  varga1962iterative,
  title		= {Iterative analysis},
  author	= {Varga, Richard S},
  year		= {1962},
  publisher	= {Springer}
}

@Article{	  versteeg1994marmousi,
  author	= {Roelof Versteeg},
  title		= {The Marmousi experience: Velocity model determination on a
		  synthetic complex data set},
  journal	= {The Leading Edge},
  volume	= {13},
  number	= {9},
  pages		= {927-936},
  year		= {1994},
  doi		= {10.1190/1.1437051},
  url		= { https://doi.org/10.1190/1.1437051
		  
		  },
  abstract	= { The motivation behind seismic data acquisition and
		  processing is simple—to obtain a depth image of the
		  earth—but performing this process correctly is extremely
		  difficult. A number of well known processing tasks (such as
		  static corrections, deconvolution, multiple elimination,
		  velocity estimation, and migration) have to be executed,
		  and each directly influences the final result. However, the
		  success of the velocity estimation is paramount and
		  critical, and large amounts of man/CPU hours are devoted to
		  it. }
}

@book{versteeg2007introduction,
	title={An introduction to computational fluid dynamics: the finite volume method},
	author={Versteeg, Henk Kaarle and Malalasekera, Weeratunge},
	year={2007},
	publisher={Pearson education}
}


@Article{	  walker1996mpi,
  title		= {MPI: a standard message passing interface},
  author	= {Walker, David W and Dongarra, Jack J},
  journal	= {Supercomputer},
  volume	= {12},
  pages		= {56--68},
  year		= {1996},
  publisher	= {ASFRA BV}
}

@InProceedings{	  whigham1995grammatically,
  title		= {Grammatically-based genetic programming},
  author	= {Whigham, Peter A. and others},
  booktitle	= {Proceedings of the workshop on genetic programming: from
		  theory to real-world applications},
  volume	= {16},
  number	= {3},
  pages		= {33-41},
  year		= {1995}
}

@Book{		  wienands2004practical,
  title		= {Practical Fourier analysis for multigrid methods},
  author	= {Wienands, Roman and Joppich, Wolfgang},
  year		= {2004},
  publisher	= {CRC press}
}

@Article{	  williams2009roofline,
  author	= {Williams, Samuel and Waterman, Andrew and Patterson,
		  David},
  title		= {Roofline: An Insightful Visual Performance Model for
		  Multicore Architectures},
  year		= {2009},
  issue_date	= {April 2009},
  publisher	= {Association for Computing Machinery},
  address	= {New York, NY, USA},
  volume	= {52},
  number	= {4},
  issn		= {0001-0782},
  url		= {https://doi.org/10.1145/1498765.1498785},
  doi		= {10.1145/1498765.1498785},
  journal	= {Commun. ACM},
  month		= apr,
  pages		= {65–76},
  numpages	= {12}
}

@Article{	  xu2017algebraic,
  title		= {Algebraic multigrid methods},
  volume	= {26},
  doi		= {10.1017/S0962492917000083},
  journal	= {Acta Numerica},
  publisher	= {Cambridge University Press},
  author	= {Xu, Jinchao and Zikatanov, Ludmil},
  year		= {2017},
  pages		= {591–721}
}

@book{zienkiewicz2005finite,
	title={The finite element method: its basis and fundamentals},
	author={Zienkiewicz, Olek C. and Taylor, Robert Leroy and Zhu, Jian Z.},
	year={2005},
	publisher={Elsevier}
}

